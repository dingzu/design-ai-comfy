import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class AzureOpenAIImageEditNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "Azure OpenAI APIå¯†é’¥"
                }),
                "endpoint": ("STRING", {
                    "default": "https://xiaolvgongcheng-ee-openai-swedencentral.openai.azure.com/",
                    "tooltip": "Azure OpenAI ç«¯ç‚¹ URL"
                }),
                "deployment_name": ("STRING", {
                    "default": "xiaolvgongcheng-ee-openai-swedencentral-gpt-image-1",
                    "tooltip": "Azure OpenAI éƒ¨ç½²åç§°"
                }),
                "api_version": ("STRING", {
                    "default": "2025-04-01-preview",
                    "tooltip": "Azure OpenAI API ç‰ˆæœ¬"
                }),
                "image": ("IMAGE", {
                    "tooltip": "å¾…ç¼–è¾‘çš„åŸå§‹å›¾åƒ"
                }),
                "prompt": ("STRING", {
                    "default": "Add blue sky",
                    "multiline": True,
                    "tooltip": "ç¼–è¾‘æè¿°æç¤ºè¯"
                }),
                "image_count": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡"
                }),
                "image_size": (["1024x1024", "1024x1536", "1536x1024"], {
                    "default": "1024x1024",
                    "tooltip": "è¾“å‡ºå›¾åƒå°ºå¯¸"
                }),
                "quality": (["low", "medium", "high"], {
                    "default": "high",
                    "tooltip": "å›¾åƒè´¨é‡"
                }),
                "output_format": (["PNG", "JPEG"], {
                    "default": "PNG",
                    "tooltip": "è¾“å‡ºæ ¼å¼"
                }),
                "max_file_size_mb": ("FLOAT", {
                    "default": 4.0,
                    "min": 1.0,
                    "max": 10.0,
                    "step": 0.5,
                    "tooltip": "å›¾ç‰‡å‹ç¼©çš„æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé¿å…Payload Too Largeé”™è¯¯"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                })
            },
            "optional": {
                "mask": ("MASK", {
                    "tooltip": "ç¼–è¾‘é®ç½©ï¼ˆå¯é€‰ï¼‰ã€‚ç™½è‰²åŒºåŸŸè¡¨ç¤ºè¦ç¼–è¾‘çš„éƒ¨åˆ†ï¼Œä¸æä¾›åˆ™ç¼–è¾‘æ•´ä¸ªå›¾åƒ"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "edit_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        pass

    def tensor_to_pil(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
        # å¤„ç†batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor[0]
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        np_image = tensor.cpu().numpy()
        if np_image.max() <= 1.0:
            np_image = (np_image * 255).astype(np.uint8)
        else:
            np_image = np.clip(np_image, 0, 255).astype(np.uint8)
        
        return Image.fromarray(np_image)

    def mask_to_pil(self, mask_tensor, target_size=None):
        """å°†MASK tensorè½¬æ¢ä¸ºPILå›¾åƒï¼ˆå¸¦alphaé€šé“çš„PNGæ ¼å¼ï¼‰"""
        # å¤„ç†batchç»´åº¦
        if len(mask_tensor.shape) == 3:
            mask_tensor = mask_tensor[0]  # å–ç¬¬ä¸€ä¸ªbatch
        elif len(mask_tensor.shape) == 4:
            mask_tensor = mask_tensor[0, 0]  # å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªé€šé“
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        mask_np = mask_tensor.cpu().numpy()
        if mask_np.max() <= 1.0:
            mask_np = (mask_np * 255).astype(np.uint8)
        else:
            mask_np = np.clip(mask_np, 0, 255).astype(np.uint8)
        
        # åˆ›å»ºPILå›¾åƒä»maskæ•°æ®
        height, width = mask_np.shape
        mask_pil = Image.fromarray(mask_np, mode='L')
        
        # å¦‚æœæä¾›äº†ç›®æ ‡å°ºå¯¸ï¼Œè°ƒæ•´é®ç½©å°ºå¯¸ä»¥åŒ¹é…åŸå§‹å›¾åƒ
        if target_size is not None and (width, height) != target_size:
            print(f"[Azure OpenAI ç¼–è¾‘] è°ƒæ•´é®ç½©å°ºå¯¸ä» {(width, height)} åˆ° {target_size}")
            mask_pil = mask_pil.resize(target_size, Image.Resampling.LANCZOS)
        
        return mask_pil

    def compress_image(self, image, max_size_mb=4.0, format="JPEG", quality=85, target_size=None):
        """å‹ç¼©å›¾åƒåˆ°æŒ‡å®šå¤§å°ä»¥ä¸‹ï¼Œå¯é€‰ä¿æŒç›®æ ‡å°ºå¯¸"""
        max_size_bytes = int(max_size_mb * 1024 * 1024)
        
        # å¦‚æœæ˜¯é®ç½©å›¾åƒï¼ˆå¯èƒ½éœ€è¦alphaé€šé“ï¼‰ï¼Œä¿æŒPNGæ ¼å¼
        if format == "PNG" and image.mode in ['RGBA', 'LA', 'L']:
            # å¯¹äºPNGé®ç½©ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„å‹ç¼©ç­–ç•¥
            current_quality = 9  # PNGå‹ç¼©çº§åˆ« (0-9, 9ä¸ºæœ€é«˜å‹ç¼©)
            
            # å…ˆå°è¯•ä¸ç¼©å°å°ºå¯¸ï¼Œåªè°ƒæ•´å‹ç¼©çº§åˆ«
            original_size = image.size
            scale_factor = 1.0
            
            while True:
                buffer = io.BytesIO()
                temp_image = image.copy()
                
                # å¦‚æœéœ€è¦ä¿æŒç›®æ ‡å°ºå¯¸ï¼ˆå¦‚é®ç½©å›¾åƒï¼‰ï¼Œå³ä½¿å‹ç¼©åä¹Ÿè¦è°ƒæ•´å›ç›®æ ‡å°ºå¯¸
                if target_size is not None and temp_image.size != target_size:
                    temp_image = temp_image.resize(target_size, Image.Resampling.LANCZOS)
                elif scale_factor < 1.0:
                    # åªæœ‰åœ¨æ²¡æœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶æ—¶æ‰ç¼©å°å›¾åƒ
                    new_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))
                    temp_image = temp_image.resize(new_size, Image.Resampling.LANCZOS)
                
                temp_image.save(buffer, format="PNG", optimize=True, compress_level=current_quality)
                
                if buffer.tell() <= max_size_bytes or (target_size is None and scale_factor <= 0.3):
                    buffer.seek(0)
                    final_size = temp_image.size
                    return buffer.getvalue(), final_size
                
                # å¦‚æœæœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶ï¼Œä¼˜å…ˆé™ä½å‹ç¼©è´¨é‡è€Œä¸æ˜¯ç¼©å°å°ºå¯¸
                if target_size is not None:
                    if current_quality > 0:
                        current_quality = max(0, current_quality - 1)
                    else:
                        # è´¨é‡å·²ç»åˆ°æœ€ä½ï¼Œæ¥å—å½“å‰ç»“æœ
                        buffer.seek(0)
                        final_size = temp_image.size
                        return buffer.getvalue(), final_size
                else:
                    scale_factor *= 0.8
        else:
            # å¯¹äºJPEGæ ¼å¼çš„æ™®é€šå›¾åƒ
            current_quality = quality
            scale_factor = 1.0
            original_size = image.size
            
            # ç¡®ä¿æ˜¯RGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            while current_quality >= 20:
                buffer = io.BytesIO()
                temp_image = image.copy()
                
                # å¦‚æœéœ€è¦ä¿æŒç›®æ ‡å°ºå¯¸ï¼Œè°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
                if target_size is not None and temp_image.size != target_size:
                    temp_image = temp_image.resize(target_size, Image.Resampling.LANCZOS)
                elif current_quality == 20 and scale_factor > 0.3:
                    # åªæœ‰åœ¨æ²¡æœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶æ—¶æ‰ç¼©å°å›¾åƒ
                    scale_factor *= 0.8
                    new_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))
                    temp_image = temp_image.resize(new_size, Image.Resampling.LANCZOS)
                    current_quality = quality  # é‡ç½®è´¨é‡
                
                temp_image.save(buffer, format="JPEG", quality=current_quality, optimize=True)
                
                if buffer.tell() <= max_size_bytes:
                    buffer.seek(0)
                    final_size = temp_image.size
                    return buffer.getvalue(), final_size
                
                current_quality -= 10
        
        # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œè¿”å›æœ€åçš„ç»“æœ
        buffer.seek(0)
        final_size = temp_image.size
        return buffer.getvalue(), final_size

    def edit_image(self, api_key, endpoint, deployment_name, api_version, image, prompt, 
                   image_count, image_size, quality, output_format, max_file_size_mb, timeout, mask=None):
        """
        Azure OpenAI å›¾åƒç¼–è¾‘
        """
        # ç”¨äºè°ƒè¯•çš„è¯·æ±‚ä¿¡æ¯
        debug_info = {
            "url": "",
            "headers": {},
            "files_info": {},
            "request_size": 0,
            "error": None,
            "response_status": None,
            "response_content": ""
        }
        
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                debug_info["error"] = "API KeyéªŒè¯å¤±è´¥"
                print(f"[Azure OpenAI ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·ä»Azureé—¨æˆ·è·å–APIå¯†é’¥")
            
            if not endpoint or endpoint.strip() == "":
                debug_info["error"] = "ç«¯ç‚¹éªŒè¯å¤±è´¥"
                print(f"[Azure OpenAI ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("Azure OpenAI ç«¯ç‚¹ä¸èƒ½ä¸ºç©º")
            
            if not deployment_name or deployment_name.strip() == "":
                debug_info["error"] = "éƒ¨ç½²åç§°éªŒè¯å¤±è´¥"
                print(f"[Azure OpenAI ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("éƒ¨ç½²åç§°ä¸èƒ½ä¸ºç©º")
            
            if not prompt or prompt.strip() == "":
                debug_info["error"] = "ç¼–è¾‘æè¿°éªŒè¯å¤±è´¥"
                print(f"[Azure OpenAI ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("ç¼–è¾‘æè¿°ä¸èƒ½ä¸ºç©º")

            # å¤„ç†ç«¯ç‚¹URL
            base_endpoint = endpoint.strip().rstrip('/')
            if not base_endpoint.startswith('http'):
                base_endpoint = f"https://{base_endpoint}"
            
            print(f"[Azure OpenAI ç¼–è¾‘] ä½¿ç”¨å°ºå¯¸: {image_size}")

            # è½¬æ¢è¾“å…¥å›¾åƒ
            print(f"[Azure OpenAI ç¼–è¾‘] å¼€å§‹å¤„ç†è¾“å…¥å›¾åƒ...")
            
            # è½¬æ¢åŸå§‹å›¾åƒä¸ºPIL
            input_image = self.tensor_to_pil(image)
            print(f"[Azure OpenAI ç¼–è¾‘] åŸå§‹å›¾åƒå°ºå¯¸: {input_image.size}, æ¨¡å¼: {input_image.mode}")
            
            # è½¬æ¢é®ç½©å›¾åƒä¸ºPIL
            mask_image = self.mask_to_pil(mask, input_image.size) if mask is not None else None
            if mask_image is not None:
                print(f"[Azure OpenAI ç¼–è¾‘] é®ç½©å›¾åƒå°ºå¯¸: {mask_image.size}, æ¨¡å¼: {mask_image.mode}")
                # éªŒè¯å°ºå¯¸æ˜¯å¦åŒ¹é…
                if mask_image.size != input_image.size:
                    print(f"[Azure OpenAI ç¼–è¾‘] è­¦å‘Š: é®ç½©å°ºå¯¸ {mask_image.size} ä¸åŸå§‹å›¾åƒå°ºå¯¸ {input_image.size} ä¸åŒ¹é…")
                else:
                    print(f"[Azure OpenAI ç¼–è¾‘] ç¡®è®¤: é®ç½©å°ºå¯¸ä¸åŸå§‹å›¾åƒå°ºå¯¸åŒ¹é… {input_image.size}")
            else:
                print("[Azure OpenAI ç¼–è¾‘] æœªæä¾›é®ç½©å›¾åƒï¼Œå°†ç¼–è¾‘æ•´ä¸ªåŸå§‹å›¾åƒ")

            # å‹ç¼©å›¾åƒä»¥é¿å…Payload Too Largeé”™è¯¯
            print(f"[Azure OpenAI ç¼–è¾‘] å‹ç¼©å›¾åƒï¼Œæœ€å¤§å¤§å°: {max_file_size_mb}MB")
            
            # å‹ç¼©åŸå§‹å›¾åƒ
            image_data, compressed_size = self.compress_image(
                input_image, 
                max_size_mb=max_file_size_mb * 0.6,  # ç»™åŸå§‹å›¾åƒåˆ†é…60%çš„ç©ºé—´
                format="PNG",  # Azure OpenAI è¦æ±‚PNGæ ¼å¼
                quality=85
            )
            print(f"[Azure OpenAI ç¼–è¾‘] åŸå§‹å›¾åƒå‹ç¼©åå¤§å°: {len(image_data) / 1024:.1f}KB, å°ºå¯¸: {compressed_size}")
            
            # å‹ç¼©é®ç½©å›¾åƒ
            mask_data = None
            mask_compressed_size = None
            if mask_image is not None:
                mask_data, mask_compressed_size = self.compress_image(
                    mask_image,
                    max_size_mb=max_file_size_mb * 0.4,  # ç»™é®ç½©å›¾åƒåˆ†é…40%çš„ç©ºé—´
                    format="PNG",  # é®ç½©å¿…é¡»æ˜¯PNGæ ¼å¼
                    target_size=input_image.size  # ç¡®ä¿å‹ç¼©åçš„é®ç½©å°ºå¯¸ä¸åŸå§‹å›¾åƒä¸€è‡´
                )
                print(f"[Azure OpenAI ç¼–è¾‘] é®ç½©å›¾åƒå‹ç¼©åå¤§å°: {len(mask_data) / 1024:.1f}KB, å°ºå¯¸: {mask_compressed_size}")
            else:
                print(f"[Azure OpenAI ç¼–è¾‘] è·³è¿‡é®ç½©å›¾åƒå‹ç¼©ï¼ˆæœªæä¾›é®ç½©ï¼‰")

            # æ„å»ºAzure OpenAI API URL - ä½¿ç”¨éƒ¨ç½²ç‰¹å®šçš„ç«¯ç‚¹
            url = f"{base_endpoint}/openai/deployments/{deployment_name}/images/edits?api-version={api_version}"
            debug_info["url"] = url
            
            # æ„å»ºmultipart/form-dataè¯·æ±‚ï¼ˆæŒ‰ç…§æˆåŠŸçš„curlæ ¼å¼ï¼‰
            files = {
                'image[]': ('beach.png', image_data, 'image/png'),  # ä½¿ç”¨ image[] æ ¼å¼
                'prompt': (None, prompt.strip()),
                'model': (None, 'gpt-image-1'),  # æ·»åŠ æ¨¡å‹å‚æ•°
                'n': (None, str(image_count)),
                'size': (None, image_size),
                'quality': (None, quality)
            }

            if mask_data is not None:
                files['mask'] = ('mask.png', mask_data, 'image/png')
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼ˆrequestsä¼šè‡ªåŠ¨è®¾ç½®multipart/form-dataçš„Content-Typeï¼‰
            headers = {
                "api-key": api_key.strip(),
                "User-Agent": "ComfyUI-Azure-OpenAI-Edit/1.0"
            }
            debug_info["headers"] = {k: v if k != "api-key" else "***éšè—***" for k, v in headers.items()}
            
            # è®°å½•æ–‡ä»¶ä¿¡æ¯ç”¨äºè°ƒè¯•
            debug_info["files_info"] = {
                'image[]': {
                    'filename': 'beach.png',
                    'size_kb': len(image_data) / 1024,
                    'content_type': 'image/png'
                },
                'prompt': prompt.strip(),
                'model': 'gpt-image-1',
                'n': str(image_count),
                'size': image_size,
                'quality': quality
            }
            
            if mask_data is not None:
                debug_info["files_info"]['mask'] = {
                    'filename': 'mask.png',
                    'size_kb': len(mask_data) / 1024,
                    'content_type': 'image/png'
                }
            
            total_request_size = len(image_data) + (len(mask_data) if mask_data is not None else 0)
            debug_info["request_size"] = total_request_size / 1024  # KB
            
            print(f"[Azure OpenAI ç¼–è¾‘] å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å‚æ•°:")
            print(f"  - deployment: {deployment_name}")
            print(f"  - api_version: {api_version}")
            print(f"  - model: gpt-image-1")
            print(f"  - prompt: {prompt.strip()}")
            print(f"  - n: {image_count}")
            print(f"  - size: {image_size}")
            print(f"  - quality: {quality}")
            print(f"  - åŸå§‹å›¾åƒ: {len(image_data) / 1024:.1f}KB")
            if mask_data is not None:
                print(f"  - é®ç½©å›¾åƒ: {len(mask_data) / 1024:.1f}KB")
            print(f"  - æ€»è¯·æ±‚å¤§å°: {total_request_size / 1024:.1f}KB")
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                url,
                headers=headers,
                files=files,
                timeout=timeout
            )
            
            debug_info["response_status"] = response.status_code
            print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            try:
                response_data = response.json()
                debug_info["response_content"] = json.dumps(response_data, ensure_ascii=False, indent=2)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
                response_text = response.text if response.text else "ç©ºå“åº”"
                debug_info["response_content"] = response_text
                debug_info["error"] = f"JSONè§£æå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                
                print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”å†…å®¹: {response_text}")
                print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[Azure OpenAI ç¼–è¾‘] ==================")
                
                if response.status_code == 404:
                    raise ValueError(f"APIç«¯ç‚¹ä¸å­˜åœ¨ (404): {url}\nå“åº”å†…å®¹: {response_text}\n\nğŸ’¡ å»ºè®®: \n1. æ£€æŸ¥Azure OpenAIç«¯ç‚¹æ˜¯å¦æ­£ç¡®\n2. ç¡®è®¤éƒ¨ç½²åç§°æ˜¯å¦æ­£ç¡®\n3. ç¡®è®¤APIç‰ˆæœ¬æ˜¯å¦æ”¯æŒå›¾åƒç¼–è¾‘åŠŸèƒ½")
                elif response.status_code == 401:
                    raise ValueError(f"è®¤è¯å¤±è´¥ (401): {response_text}\n\nğŸ’¡ å»ºè®®: \n1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®\n2. ç¡®è®¤APIå¯†é’¥æ˜¯å¦æœ‰æƒé™è®¿é—®æ­¤éƒ¨ç½²")
                else:
                    raise ValueError(f"æ— æ•ˆçš„JSONå“åº” (çŠ¶æ€ç : {response.status_code}): {response_text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                debug_info["error"] = f"APIé”™è¯¯ [{error_code}]: {error_msg} (ç±»å‹: {error_type})"
                
                print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[Azure OpenAI ç¼–è¾‘] ==================")
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'payload too large' in error_msg.lower() or response.status_code == 413:
                    error_msg += f"\n\nğŸ’¡ å»ºè®®: è¯·æ±‚ä½“è¿‡å¤§ï¼ˆå½“å‰çº¦{total_request_size / 1024:.1f}KBï¼‰"
                    error_msg += f"\n  - å°è¯•å‡å° max_file_size_mb å‚æ•°ï¼ˆå½“å‰: {max_file_size_mb}MBï¼‰"
                    error_msg += f"\n  - æˆ–ä½¿ç”¨æ›´å°çš„è¾“å…¥å›¾åƒ"
                elif 'invalid image' in error_msg.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: å›¾åƒæ ¼å¼ä¸æ­£ç¡®"
                    error_msg += "\n  - ç¡®ä¿å›¾åƒæ˜¯æœ‰æ•ˆçš„PNGæ ¼å¼"
                    error_msg += "\n  - å›¾åƒå°ºå¯¸åº”å°äº4MB"
                elif 'invalid mask' in error_msg.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: é®ç½©å›¾åƒæ ¼å¼ä¸æ­£ç¡®"
                    error_msg += "\n  - é®ç½©å›¾åƒå¿…é¡»æ˜¯PNGæ ¼å¼"
                    error_msg += "\n  - é®ç½©å¿…é¡»ä¸åŸå§‹å›¾åƒå…·æœ‰ç›¸åŒçš„å°ºå¯¸"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼Œä»Azureé—¨æˆ·è·å–æ­£ç¡®çš„APIå¯†é’¥"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                elif response.status_code == 403:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æƒé™ä¸è¶³ï¼Œæ£€æŸ¥APIå¯†é’¥çš„æƒé™å’Œéƒ¨ç½²è®¿é—®æƒé™"
                
                raise ValueError(f"APIé”™è¯¯ [{error_code}]: {error_msg}")
            
            # å¤„ç†ç¼–è¾‘åçš„å›¾åƒ
            images_tensor = []
            image_data_list = response_data.get('data', [])
            
            if not image_data_list:
                debug_info["error"] = "å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®"
                print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[Azure OpenAI ç¼–è¾‘] ==================")
                raise ValueError("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
            
            print(f"[Azure OpenAI ç¼–è¾‘] æˆåŠŸç”Ÿæˆ {len(image_data_list)} å¼ å›¾åƒ")
            
            for idx, item in enumerate(image_data_list):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_bytes = base64.b64decode(b64_data)
                    result_image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if result_image.mode != 'RGB':
                        result_image = result_image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(result_image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[Azure OpenAI ç¼–è¾‘] å›¾åƒ {idx + 1}: {result_image.size}, æ¨¡å¼: {result_image.mode}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    print(f"[Azure OpenAI ç¼–è¾‘] æ”¶åˆ°å›¾åƒURL: {item['url']}")
                    try:
                        # ä¸‹è½½URLå›¾åƒ
                        img_response = requests.get(item['url'], timeout=30)
                        if img_response.ok:
                            result_image = Image.open(io.BytesIO(img_response.content))
                            
                            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                            if result_image.mode != 'RGB':
                                result_image = result_image.convert('RGB')
                            
                            # è½¬æ¢ä¸ºtensor
                            image_np = np.array(result_image).astype(np.float32) / 255.0
                            image_tensor = torch.from_numpy(image_np)[None,]
                            images_tensor.append(image_tensor)
                            
                            print(f"[Azure OpenAI ç¼–è¾‘] å›¾åƒ {idx + 1}: {result_image.size}, æ¨¡å¼: {result_image.mode}")
                        else:
                            print(f"[Azure OpenAI ç¼–è¾‘] ä¸‹è½½å›¾åƒå¤±è´¥: {img_response.status_code}")
                    except Exception as e:
                        print(f"[Azure OpenAI ç¼–è¾‘] å¤„ç†URLå›¾åƒå¤±è´¥: {str(e)}")
            
            if not images_tensor:
                debug_info["error"] = "æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®"
                print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[Azure OpenAI ç¼–è¾‘] ==================")
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage_info = f"Azure OpenAI å›¾åƒç¼–è¾‘ä½¿ç”¨æƒ…å†µ:\n"
            usage_info += f"- ç«¯ç‚¹: {base_endpoint}\n"
            usage_info += f"- éƒ¨ç½²: {deployment_name}\n"
            usage_info += f"- APIç‰ˆæœ¬: {api_version}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}\n"
            usage_info += f"- åŸå§‹å›¾åƒå‹ç¼©: {compressed_size} -> {len(image_data) / 1024:.1f}KB\n"
            if mask_data is not None:
                usage_info += f"- é®ç½©å›¾åƒå‹ç¼©: {mask_compressed_size} -> {len(mask_data) / 1024:.1f}KB"
            else:
                usage_info += f"- é®ç½©å›¾åƒ: æœªæä¾›ï¼ˆç¼–è¾‘æ•´ä¸ªå›¾åƒï¼‰"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[Azure OpenAI ç¼–è¾‘] å›¾åƒç¼–è¾‘å®Œæˆ")
            print(f"[Azure OpenAI ç¼–è¾‘] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            debug_info["error"] = f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰"
            print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[Azure OpenAI ç¼–è¾‘] ==================")
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç¼–è¾‘å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            debug_info["error"] = "ç½‘ç»œè¿æ¥é”™è¯¯"
            print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[Azure OpenAI ç¼–è¾‘] ==================")
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. Azure OpenAIç«¯ç‚¹åœ°å€æ˜¯å¦å¯è®¿é—®\n3. é˜²ç«å¢™è®¾ç½®")
        except requests.exceptions.RequestException as e:
            debug_info["error"] = f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
            print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[Azure OpenAI ç¼–è¾‘] ==================")
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            debug_info["error"] = f"æœªçŸ¥å¼‚å¸¸: {str(e)}"
            print(f"[Azure OpenAI ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[Azure OpenAI ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[Azure OpenAI ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            if debug_info["response_status"]:
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
            if debug_info["response_content"]:
                print(f"[Azure OpenAI ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
            print(f"[Azure OpenAI ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[Azure OpenAI ç¼–è¾‘] ==================")
            raise ValueError(f"å›¾åƒç¼–è¾‘å¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "AzureOpenAIImageEdit": AzureOpenAIImageEditNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AzureOpenAIImageEdit": "Azure OpenAI å›¾åƒç¼–è¾‘"
}

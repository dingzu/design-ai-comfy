import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class WanQingJiMeng40TextToImageNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc", "overseas", "domestic"], {
                    "default": "staging",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "prompt": ("STRING", {
                    "default": "æ˜Ÿé™…ç©¿è¶Šï¼Œé»‘æ´ï¼Œé»‘æ´é‡Œå†²å‡ºä¸€è¾†å¿«æ”¯ç¦»ç ´ç¢çš„å¤å¤åˆ—è½¦ï¼ŒæŠ¢è§†è§‰å†²å‡»åŠ›ï¼Œç”µå½±å¤§ç‰‡ï¼Œæœ«æ—¥æ—¢è§†æ„Ÿï¼ŒåŠ¨æ„Ÿï¼Œå¯¹æ¯”è‰²ï¼Œocæ¸²æŸ“ï¼Œå…‰çº¿è¿½è¸ªï¼ŒåŠ¨æ€æ¨¡ç³Šï¼Œæ™¯æ·±ï¼Œè¶…ç°å®ä¸»ä¹‰ï¼Œæ·±è“ï¼Œç”»é¢é€šè¿‡ç»†è…»çš„ä¸°å¯Œçš„è‰²å½©å±‚æ¬¡å¡‘é€ ä¸»ä½“ä¸åœºæ™¯ï¼Œè´¨æ„ŸçœŸå®ï¼Œæš—é»‘é£èƒŒæ™¯çš„å…‰å½±æ•ˆæœè¥é€ å‡ºæ°›å›´ï¼Œæ•´ä½“å…¼å…·è‰ºæœ¯å¹»æƒ³æ„Ÿï¼Œå¤¸å¼ çš„å¹¿è§’é€è§†æ•ˆæœï¼Œè€€å…‰ï¼Œåå°„ï¼Œæè‡´çš„å…‰å½±ï¼Œå¼ºå¼•åŠ›ï¼Œåå™¬",
                    "multiline": True,
                    "tooltip": "å›¾åƒæè¿°æç¤ºè¯ï¼Œå»ºè®®ç»“æ„ï¼šé£æ ¼å…³é”®è¯ + ä¸»è¦ç¾å­¦å…³é”®è¯ + è§†è§‰å†…å®¹ + è§†è§‰ä¸Šä¸‹æ–‡ + è¡¥å……ç¾å­¦å…³é”®è¯"
                }),
                "size": (["4K", "2K", "1K", "1024x1024", "1024x1536", "1536x1024"], {
                    "default": "2K",
                    "tooltip": "å›¾åƒå°ºå¯¸ï¼ˆ4Kæ”¯æŒè¶…é«˜æ¸…è¾“å‡ºï¼‰"
                }),
                "response_format": (["url", "b64_json"], {
                    "default": "url",
                    "tooltip": "å“åº”æ ¼å¼"
                }),
                "sequential_image_generation": (["enabled", "disabled"], {
                    "default": "disabled",
                    "tooltip": "é¡ºåºå›¾åƒç”Ÿæˆ"
                }),
                "stream": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æµå¼å“åº”"
                }),
                "watermark": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "use_proxy": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦ä½¿ç”¨ä»£ç†æœåŠ¡å™¨"
                }),
                "custom_base_url": ("STRING", {
                    "default": "",
                    "tooltip": "è‡ªå®šä¹‰APIåŸºç¡€URLï¼ˆä¼˜å…ˆçº§é«˜äºç¯å¢ƒé€‰æ‹©ï¼‰"
                }),
                "custom_endpoint": ("STRING", {
                    "default": "/llm-serve/v1/images/generations",
                    "tooltip": "è‡ªå®šä¹‰APIç«¯ç‚¹è·¯å¾„"
                })
            },
            "optional": {
                "n": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡ï¼ˆ1-4å¼ ï¼‰"
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "step": 1,
                    "tooltip": "éšæœºç§å­ï¼Œ-1ä¸ºéšæœºç”Ÿæˆ"
                }),
                "negative_prompt": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "tooltip": "è´Ÿé¢æç¤ºè¯ï¼Œæè¿°ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹"
                }),
                "quality": (["hd", "standard"], {
                    "default": "hd",
                    "tooltip": "å›¾åƒè´¨é‡ï¼šhdï¼ˆé«˜æ¸…ï¼‰æˆ– standardï¼ˆæ ‡å‡†ï¼‰"
                }),
                "style": (["natural", "vivid"], {
                    "default": "vivid",
                    "tooltip": "å›¾åƒé£æ ¼ï¼šnaturalï¼ˆè‡ªç„¶ï¼‰æˆ– vividï¼ˆç”ŸåŠ¨ï¼‰"
                }),
                "guidance_scale": ("FLOAT", {
                    "default": 7.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.5,
                    "tooltip": "å¼•å¯¼å¼ºåº¦ï¼Œæ§åˆ¶ç”Ÿæˆå›¾åƒä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦"
                }),
                "steps": ("INT", {
                    "default": 50,
                    "min": 10,
                    "max": 100,
                    "step": 1,
                    "tooltip": "æ¨ç†æ­¥æ•°ï¼Œæ›´å¤šæ­¥æ•°é€šå¸¸å¾—åˆ°æ›´é«˜è´¨é‡å›¾åƒ"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "generate_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod.corp.kuaishou.com", 
            "idc": "http://llm-gateway.internal",
            "overseas": "http://llm-gateway-sgp.internal",
            "domestic": "http://llm-gateway.internal"
        }

    def generate_image(self, environment, api_key, prompt, size, response_format, 
                      sequential_image_generation, stream, watermark, timeout, use_proxy, 
                      custom_base_url="", custom_endpoint="/llm-serve/v1/images/generations",
                      n=1, seed=-1, negative_prompt="", quality="hd", style="vivid", 
                      guidance_scale=7.5, steps=50):
        """
        ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ - æ”¯æŒ4Kè¶…é«˜æ¸…ã€å¤šå›¾ç”Ÿæˆã€é£æ ¼æ§åˆ¶ç­‰é«˜çº§åŠŸèƒ½
        
        æ”¯æŒçš„åŠŸèƒ½:
        - 4Kè¶…é«˜æ¸…å›¾åƒç”Ÿæˆ
        - å¤šå›¾åƒç”Ÿæˆ (1-4å¼ )
        - å¯é‡å¤ç»“æœ (ç§å­æ§åˆ¶)
        - è´Ÿé¢æç¤ºè¯è¿‡æ»¤
        - è´¨é‡å’Œé£æ ¼æ§åˆ¶
        - ç²¾ç»†çš„å¼•å¯¼å‚æ•°è°ƒèŠ‚
        """
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key")
            
            if not prompt or prompt.strip() == "":
                raise ValueError("å›¾åƒæè¿°ä¸èƒ½ä¸ºç©º")

            # æ„å»ºURL - ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„base_url
            if custom_base_url and custom_base_url.strip():
                base_url = custom_base_url.strip().rstrip('/')
            else:
                base_url = self.environments[environment]
            
            # ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹è·¯å¾„
            endpoint = custom_endpoint.strip() if custom_endpoint.strip() else "/llm-serve/v1/images/generations"
            endpoint = endpoint.lstrip('/')  # ç§»é™¤å¼€å¤´çš„æ–œæ 
            url = f"{base_url}/{endpoint}"
            
            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "model": "doubao-seedream-4-0-250828",
                "prompt": prompt.strip(),
                "size": size,
                "sequential_image_generation": sequential_image_generation,
                "stream": stream,
                "response_format": response_format,
                "watermark": watermark
            }
            
            # æ·»åŠ å›¾åƒæ•°é‡
            if n > 1:
                payload["n"] = n
                
            # æ·»åŠ éšæœºç§å­
            if seed != -1:
                payload["seed"] = seed
                
            # æ·»åŠ è´Ÿé¢æç¤ºè¯
            if negative_prompt and negative_prompt.strip():
                payload["negative_prompt"] = negative_prompt.strip()
                
            # æ·»åŠ è´¨é‡è®¾ç½®
            if quality != "hd":
                payload["quality"] = quality
                
            # æ·»åŠ é£æ ¼è®¾ç½®
            if style != "vivid":
                payload["style"] = style
                
            # æ·»åŠ å¼•å¯¼å¼ºåº¦
            if guidance_scale != 7.5:
                payload["guidance_scale"] = guidance_scale
                
            # æ·»åŠ æ¨ç†æ­¥æ•°
            if steps != 50:
                payload["steps"] = steps
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "x-api-key": api_key.strip(),
                "Content-Type": "application/json",
                "User-Agent": "ComfyUI-JiMeng-4.0-T2I/1.0"
            }
            
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False, indent=2)}")
            
            # é…ç½®ä»£ç†
            request_kwargs = {
                "headers": headers,
                "json": payload,
                "timeout": timeout
            }
            if use_proxy:
                request_kwargs["proxies"] = {"http": None, "https": None}
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, **request_kwargs)
            
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                response_text = response.text if response.text else "ç©ºå“åº”"
                print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] å“åº”å†…å®¹: {response_text}")
                raise ValueError(f"æ— æ•ˆçš„JSONå“åº” (çŠ¶æ€ç : {response.status_code}): {response_text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'unknown_parameter' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå‚æ•°æ˜¯å¦æ­£ç¡®ï¼ŒæŸäº›å‚æ•°å¯èƒ½ä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ"
                elif 'invalid_value' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…"
                elif 'invalid_request_error' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå¿…éœ€å‚æ•°"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆï¼Œè”ç³» @äºæ·¼ è·å–æ­£ç¡®çš„ä¸‡æ“ç½‘å…³key"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                
                raise ValueError(f"APIé”™è¯¯ [{error_code}]: {error_msg}")
            
            # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
            images_tensor = []
            image_data = response_data.get('data', [])
            
            if not image_data:
                raise ValueError("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
            
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] æˆåŠŸç”Ÿæˆ {len(image_data)} å¼ å›¾åƒ")
            
            for idx, item in enumerate(image_data):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_size = item.get('size', 'æœªçŸ¥')
                    print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] APIè¿”å›çš„å›¾åƒå°ºå¯¸: {image_size}")
                    
                    image_bytes = base64.b64decode(b64_data)
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if image.mode != 'RGB':
                        image = image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] å›¾åƒ {idx + 1}: {image.size}, æ¨¡å¼: {image.mode}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    image_url = item['url']
                    image_size = item.get('size', 'æœªçŸ¥')
                    print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] æ”¶åˆ°å›¾åƒURL: {image_url}")
                    print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] APIè¿”å›çš„å›¾åƒå°ºå¯¸: {image_size}")
                    
                    try:
                        # é…ç½®ä»£ç†
                        download_kwargs = {"timeout": 30}
                        if use_proxy:
                            download_kwargs["proxies"] = {"http": None, "https": None}
                        
                        img_response = requests.get(image_url, **download_kwargs)
                        img_response.raise_for_status()
                        image = Image.open(io.BytesIO(img_response.content))
                        
                        # è½¬æ¢ä¸ºRGB
                        if image.mode != 'RGB':
                            image = image.convert('RGB')
                        
                        # è½¬æ¢ä¸ºtensor
                        image_np = np.array(image).astype(np.float32) / 255.0
                        image_tensor = torch.from_numpy(image_np)[None,]
                        images_tensor.append(image_tensor)
                        
                        print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] ä¸‹è½½å›¾åƒ {idx + 1}: å®é™…å°ºå¯¸{image.size}, æ¨¡å¼: {image.mode}")
                        
                    except Exception as e:
                        print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] ä¸‹è½½å›¾åƒå¤±è´¥: {str(e)}")
                        continue
            
            if not images_tensor:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage = response_data.get('usage', {})
            usage_info = f"ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ç»“æœ:\n"
            usage_info += f"- æ¨¡å‹: doubao-seedream-4-0-250828\n"
            usage_info += f"- è¯·æ±‚å°ºå¯¸: {size}\n"
            
            # æ˜¾ç¤ºå®é™…ç”Ÿæˆçš„å›¾åƒå°ºå¯¸
            actual_sizes = []
            for item in image_data:
                if 'size' in item:
                    actual_sizes.append(item['size'])
            if actual_sizes:
                usage_info += f"- å®é™…å°ºå¯¸: {', '.join(actual_sizes)}\n"
            
            usage_info += f"- å“åº”æ ¼å¼: {response_format}\n"
            usage_info += f"- è¯·æ±‚å›¾åƒæ•°é‡: {n}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}\n"
            
            if seed != -1:
                usage_info += f"- éšæœºç§å­: {seed}\n"
            if negative_prompt and negative_prompt.strip():
                usage_info += f"- è´Ÿé¢æç¤ºè¯: {negative_prompt.strip()[:50]}{'...' if len(negative_prompt.strip()) > 50 else ''}\n"
            if quality != "hd":
                usage_info += f"- å›¾åƒè´¨é‡: {quality}\n"
            if style != "vivid":
                usage_info += f"- å›¾åƒé£æ ¼: {style}\n"
            if guidance_scale != 7.5:
                usage_info += f"- å¼•å¯¼å¼ºåº¦: {guidance_scale}\n"
            if steps != 50:
                usage_info += f"- æ¨ç†æ­¥æ•°: {steps}\n"
                
            usage_info += f"- é¡ºåºç”Ÿæˆ: {sequential_image_generation}\n"
            usage_info += f"- æµå¼å“åº”: {'æ˜¯' if stream else 'å¦'}\n"
            usage_info += f"- æ°´å°: {'æ˜¯' if watermark else 'å¦'}\n"
            
            if usage:
                usage_info += f"- ç”Ÿæˆå›¾åƒç»Ÿè®¡: {usage.get('generated_images', 0)}\n"
                usage_info += f"- è¾“å‡ºToken: {usage.get('output_tokens', 0)}\n"
                usage_info += f"- æ€»è®¡Token: {usage.get('total_tokens', usage.get('output_tokens', 0))}"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] å›¾åƒç”Ÿæˆå®Œæˆ")
            print(f"[ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            raise ValueError(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "WanQingJiMeng40TextToImage": WanQingJiMeng40TextToImageNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanQingJiMeng40TextToImage": "ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾"
}

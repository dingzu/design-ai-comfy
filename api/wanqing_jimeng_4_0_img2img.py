import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class WanQingJiMeng40ImageToImageNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc", "overseas", "domestic"], {
                    "default": "staging",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "prompt": ("STRING", {
                    "default": "ç”Ÿæˆç‹—ç‹—è¶´åœ¨è‰åœ°ä¸Šçš„è¿‘æ™¯ç”»é¢",
                    "multiline": True,
                    "tooltip": "å›¾åƒç¼–è¾‘æè¿°æç¤ºè¯ï¼Œå»ºè®®ç»“æ„ï¼šé£æ ¼å…³é”®è¯ + ä¸»è¦ç¾å­¦å…³é”®è¯ + è§†è§‰å†…å®¹ + è§†è§‰ä¸Šä¸‹æ–‡ + è¡¥å……ç¾å­¦å…³é”®è¯"
                }),
                "size": (["4K", "2K", "1K", "1024x1024", "1024x1536", "1536x1024", "adaptive"], {
                    "default": "2K",
                    "tooltip": "å›¾åƒå°ºå¯¸ï¼ˆ4Kæ”¯æŒè¶…é«˜æ¸…è¾“å‡ºï¼Œadaptiveè‡ªé€‚åº”è¾“å…¥å›¾åƒå°ºå¯¸ï¼‰"
                }),
                "response_format": (["url", "b64_json"], {
                    "default": "url",
                    "tooltip": "å“åº”æ ¼å¼"
                }),
                "sequential_image_generation": (["enabled", "disabled"], {
                    "default": "disabled",
                    "tooltip": "é¡ºåºå›¾åƒç”Ÿæˆ"
                }),
                "stream": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æµå¼å“åº”"
                }),
                "watermark": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "use_proxy": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦ä½¿ç”¨ä»£ç†æœåŠ¡å™¨"
                }),
                "custom_base_url": ("STRING", {
                    "default": "",
                    "tooltip": "è‡ªå®šä¹‰APIåŸºç¡€URLï¼ˆä¼˜å…ˆçº§é«˜äºç¯å¢ƒé€‰æ‹©ï¼‰"
                }),
                "custom_endpoint": ("STRING", {
                    "default": "/llm-serve/v1/images/generations",
                    "tooltip": "è‡ªå®šä¹‰APIç«¯ç‚¹è·¯å¾„"
                })
            },
            "optional": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾åƒï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å›¾åƒURLï¼‰"
                }),
                "image_url": ("STRING", {
                    "default": "https://ark-project.tos-cn-beijing.volces.com/doc_image/seedream4_imageToimage.png",
                    "tooltip": "å›¾åƒURLï¼ˆå½“æœªæä¾›è¾“å…¥å›¾åƒæ—¶ä½¿ç”¨ï¼‰"
                }),
                "n": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡ï¼ˆ1-4å¼ ï¼‰"
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "step": 1,
                    "tooltip": "éšæœºç§å­ï¼Œ-1ä¸ºéšæœºç”Ÿæˆ"
                }),
                "negative_prompt": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "tooltip": "è´Ÿé¢æç¤ºè¯ï¼Œæè¿°ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹"
                }),
                "quality": (["hd", "standard"], {
                    "default": "hd",
                    "tooltip": "å›¾åƒè´¨é‡ï¼šhdï¼ˆé«˜æ¸…ï¼‰æˆ– standardï¼ˆæ ‡å‡†ï¼‰"
                }),
                "style": (["natural", "vivid"], {
                    "default": "vivid",
                    "tooltip": "å›¾åƒé£æ ¼ï¼šnaturalï¼ˆè‡ªç„¶ï¼‰æˆ– vividï¼ˆç”ŸåŠ¨ï¼‰"
                }),
                "guidance_scale": ("FLOAT", {
                    "default": 7.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.5,
                    "tooltip": "å¼•å¯¼å¼ºåº¦ï¼Œæ§åˆ¶ç”Ÿæˆå›¾åƒä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦"
                }),
                "steps": ("INT", {
                    "default": 50,
                    "min": 10,
                    "max": 100,
                    "step": 1,
                    "tooltip": "æ¨ç†æ­¥æ•°ï¼Œæ›´å¤šæ­¥æ•°é€šå¸¸å¾—åˆ°æ›´é«˜è´¨é‡å›¾åƒ"
                }),
                "strength": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "tooltip": "å›¾åƒå˜åŒ–å¼ºåº¦ï¼Œ0.0ä¿æŒåŸå›¾ï¼Œ1.0å®Œå…¨é‡æ–°ç”Ÿæˆ"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "generate_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod.corp.kuaishou.com", 
            "idc": "http://llm-gateway.internal",
            "overseas": "http://llm-gateway-sgp.internal",
            "domestic": "http://llm-gateway.internal"
        }

    def tensor_to_base64(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºbase64ç¼–ç çš„å›¾åƒ"""
        # å¤„ç†batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor[0]
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        np_image = tensor.cpu().numpy()
        if np_image.max() <= 1.0:
            np_image = (np_image * 255).astype(np.uint8)
        else:
            np_image = np.clip(np_image, 0, 255).astype(np.uint8)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(np_image)
        
        # è½¬æ¢ä¸ºbase64
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        buffer.seek(0)
        
        # è¿”å›data URIæ ¼å¼ï¼Œç«å±±å¼•æ“APIæœŸæœ›è¿™ç§æ ¼å¼
        base64_string = base64.b64encode(buffer.getvalue()).decode('utf-8')
        return f"data:image/jpeg;base64,{base64_string}"

    def generate_image(self, environment, api_key, prompt, size, response_format, 
                      sequential_image_generation, stream, watermark, timeout, use_proxy, 
                      custom_base_url="", custom_endpoint="/llm-serve/v1/images/generations",
                      image=None, image_url=None, n=1, seed=-1, negative_prompt="", 
                      quality="hd", style="vivid", guidance_scale=7.5, steps=50, strength=0.8):
        """
        ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾ - æ”¯æŒ4Kè¶…é«˜æ¸…ã€å¤šå›¾ç”Ÿæˆã€é£æ ¼æ§åˆ¶ç­‰é«˜çº§åŠŸèƒ½
        
        æ”¯æŒçš„åŠŸèƒ½:
        - 4Kè¶…é«˜æ¸…å›¾åƒç”Ÿæˆ
        - å¤šå›¾åƒç”Ÿæˆ (1-4å¼ )
        - å¯é‡å¤ç»“æœ (ç§å­æ§åˆ¶)
        - è´Ÿé¢æç¤ºè¯è¿‡æ»¤
        - è´¨é‡å’Œé£æ ¼æ§åˆ¶
        - ç²¾ç»†çš„å¼•å¯¼å‚æ•°è°ƒèŠ‚
        - å›¾åƒå˜åŒ–å¼ºåº¦æ§åˆ¶
        """
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key")
            
            if not prompt or prompt.strip() == "":
                raise ValueError("å›¾åƒç¼–è¾‘æè¿°ä¸èƒ½ä¸ºç©º")

            # å¤„ç†è¾“å…¥å›¾åƒ
            image_input = None
            if image is not None:
                # ä½¿ç”¨æä¾›çš„å›¾åƒtensor
                image_input = self.tensor_to_base64(image)
                print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] ä½¿ç”¨è¾“å…¥å›¾åƒtensorï¼Œå°ºå¯¸: {image.shape}")
                print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å›¾åƒæ ¼å¼: data URI (é•¿åº¦: {len(image_input)} å­—ç¬¦)")
            elif image_url and image_url.strip():
                # ä½¿ç”¨å›¾åƒURL
                image_input = image_url.strip()
                print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] ä½¿ç”¨å›¾åƒURL: {image_input}")
                # éªŒè¯URLæ ¼å¼
                if not (image_input.startswith('http://') or image_input.startswith('https://') or image_input.startswith('data:')):
                    print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] è­¦å‘Š: URLæ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œåº”ä»¥http://ã€https://æˆ–data:å¼€å¤´")
            else:
                raise ValueError("å¿…é¡»æä¾›è¾“å…¥å›¾åƒæˆ–å›¾åƒURL")

            # æ„å»ºURL - ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„base_url
            if custom_base_url and custom_base_url.strip():
                base_url = custom_base_url.strip().rstrip('/')
            else:
                base_url = self.environments[environment]
            
            # ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹è·¯å¾„
            endpoint = custom_endpoint.strip() if custom_endpoint.strip() else "/llm-serve/v1/images/generations"
            endpoint = endpoint.lstrip('/')  # ç§»é™¤å¼€å¤´çš„æ–œæ 
            url = f"{base_url}/{endpoint}"
            
            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "model": "doubao-seedream-4-0-250828",
                "prompt": prompt.strip(),
                "image": image_input,
                "size": size,
                "sequential_image_generation": sequential_image_generation,
                "stream": stream,
                "response_format": response_format,
                "watermark": watermark
            }
            
            # æ·»åŠ å›¾åƒæ•°é‡
            if n > 1:
                payload["n"] = n
                
            # æ·»åŠ éšæœºç§å­
            if seed != -1:
                payload["seed"] = seed
                
            # æ·»åŠ è´Ÿé¢æç¤ºè¯
            if negative_prompt and negative_prompt.strip():
                payload["negative_prompt"] = negative_prompt.strip()
                
            # æ·»åŠ è´¨é‡è®¾ç½®
            if quality != "hd":
                payload["quality"] = quality
                
            # æ·»åŠ é£æ ¼è®¾ç½®
            if style != "vivid":
                payload["style"] = style
                
            # æ·»åŠ å¼•å¯¼å¼ºåº¦
            if guidance_scale != 7.5:
                payload["guidance_scale"] = guidance_scale
                
            # æ·»åŠ æ¨ç†æ­¥æ•°
            if steps != 50:
                payload["steps"] = steps
                
            # æ·»åŠ å›¾åƒå˜åŒ–å¼ºåº¦
            if strength != 0.8:
                payload["strength"] = strength
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "x-api-key": api_key.strip(),
                "Content-Type": "application/json",
                "User-Agent": "ComfyUI-JiMeng-4.0-I2I/1.0"
            }
            
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] è¯·æ±‚å‚æ•°:")
            print(f"  - model: doubao-seedream-4-0-250828")
            print(f"  - prompt: {prompt.strip()}")
            print(f"  - image: {'base64æ•°æ®' if image is not None else image_input}")
            print(f"  - size: {size}")
            print(f"  - n: {n}")
            if seed != -1:
                print(f"  - seed: {seed}")
            if negative_prompt and negative_prompt.strip():
                print(f"  - negative_prompt: {negative_prompt.strip()[:50]}...")
            if quality != "hd":
                print(f"  - quality: {quality}")
            if style != "vivid":
                print(f"  - style: {style}")
            if guidance_scale != 7.5:
                print(f"  - guidance_scale: {guidance_scale}")
            if steps != 50:
                print(f"  - steps: {steps}")
            if strength != 0.8:
                print(f"  - strength: {strength}")
            print(f"  - sequential_image_generation: {sequential_image_generation}")
            print(f"  - stream: {stream}")
            print(f"  - response_format: {response_format}")
            print(f"  - watermark: {watermark}")
            
            # é…ç½®ä»£ç†
            request_kwargs = {
                "headers": headers,
                "json": payload,
                "timeout": timeout
            }
            if use_proxy:
                request_kwargs["proxies"] = {"http": None, "https": None}
            
            # å‘é€è¯·æ±‚
            response = requests.post(url, **request_kwargs)
            
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                response_text = response.text if response.text else "ç©ºå“åº”"
                print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å“åº”å†…å®¹: {response_text}")
                raise ValueError(f"æ— æ•ˆçš„JSONå“åº” (çŠ¶æ€ç : {response.status_code}): {response_text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'unknown_parameter' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå‚æ•°æ˜¯å¦æ­£ç¡®ï¼ŒæŸäº›å‚æ•°å¯èƒ½ä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ"
                elif 'invalid_value' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…"
                elif 'invalid_request_error' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå¿…éœ€å‚æ•°"
                elif 'invalid_image' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¾“å…¥å›¾åƒæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæ”¯æŒå¸¸è§å›¾åƒæ ¼å¼"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆï¼Œè”ç³» @äºæ·¼ è·å–æ­£ç¡®çš„ä¸‡æ“ç½‘å…³key"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                
                raise ValueError(f"APIé”™è¯¯ [{error_code}]: {error_msg}")
            
            # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
            images_tensor = []
            image_data = response_data.get('data', [])
            
            if not image_data:
                raise ValueError("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
            
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] æˆåŠŸç”Ÿæˆ {len(image_data)} å¼ å›¾åƒ")
            
            for idx, item in enumerate(image_data):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_size = item.get('size', 'æœªçŸ¥')
                    print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] APIè¿”å›çš„å›¾åƒå°ºå¯¸: {image_size}")
                    
                    image_bytes = base64.b64decode(b64_data)
                    result_image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if result_image.mode != 'RGB':
                        result_image = result_image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(result_image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å›¾åƒ {idx + 1}: {result_image.size}, æ¨¡å¼: {result_image.mode}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    image_url_result = item['url']
                    image_size = item.get('size', 'æœªçŸ¥')
                    print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] æ”¶åˆ°å›¾åƒURL: {image_url_result}")
                    print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] APIè¿”å›çš„å›¾åƒå°ºå¯¸: {image_size}")
                    
                    try:
                        # é…ç½®ä»£ç†
                        download_kwargs = {"timeout": 30}
                        if use_proxy:
                            download_kwargs["proxies"] = {"http": None, "https": None}
                        
                        img_response = requests.get(image_url_result, **download_kwargs)
                        img_response.raise_for_status()
                        result_image = Image.open(io.BytesIO(img_response.content))
                        
                        # è½¬æ¢ä¸ºRGB
                        if result_image.mode != 'RGB':
                            result_image = result_image.convert('RGB')
                        
                        # è½¬æ¢ä¸ºtensor
                        image_np = np.array(result_image).astype(np.float32) / 255.0
                        image_tensor = torch.from_numpy(image_np)[None,]
                        images_tensor.append(image_tensor)
                        
                        print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] ä¸‹è½½å›¾åƒ {idx + 1}: å®é™…å°ºå¯¸{result_image.size}, æ¨¡å¼: {result_image.mode}")
                        
                    except Exception as e:
                        print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] ä¸‹è½½å›¾åƒå¤±è´¥: {str(e)}")
                        continue
            
            if not images_tensor:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage = response_data.get('usage', {})
            usage_info = f"ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾ç»“æœ:\n"
            usage_info += f"- æ¨¡å‹: doubao-seedream-4-0-250828\n"
            usage_info += f"- è¯·æ±‚å°ºå¯¸: {size}\n"
            
            # æ˜¾ç¤ºå®é™…ç”Ÿæˆçš„å›¾åƒå°ºå¯¸
            actual_sizes = []
            for item in image_data:
                if 'size' in item:
                    actual_sizes.append(item['size'])
            if actual_sizes:
                usage_info += f"- å®é™…å°ºå¯¸: {', '.join(actual_sizes)}\n"
            
            usage_info += f"- å“åº”æ ¼å¼: {response_format}\n"
            usage_info += f"- è¯·æ±‚å›¾åƒæ•°é‡: {n}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}\n"
            usage_info += f"- è¾“å…¥å›¾åƒ: {'Tensor' if image is not None else 'URL'}\n"
            
            if seed != -1:
                usage_info += f"- éšæœºç§å­: {seed}\n"
            if negative_prompt and negative_prompt.strip():
                usage_info += f"- è´Ÿé¢æç¤ºè¯: {negative_prompt.strip()[:50]}{'...' if len(negative_prompt.strip()) > 50 else ''}\n"
            if quality != "hd":
                usage_info += f"- å›¾åƒè´¨é‡: {quality}\n"
            if style != "vivid":
                usage_info += f"- å›¾åƒé£æ ¼: {style}\n"
            if guidance_scale != 7.5:
                usage_info += f"- å¼•å¯¼å¼ºåº¦: {guidance_scale}\n"
            if steps != 50:
                usage_info += f"- æ¨ç†æ­¥æ•°: {steps}\n"
            if strength != 0.8:
                usage_info += f"- å˜åŒ–å¼ºåº¦: {strength}\n"
                
            usage_info += f"- é¡ºåºç”Ÿæˆ: {sequential_image_generation}\n"
            usage_info += f"- æµå¼å“åº”: {'æ˜¯' if stream else 'å¦'}\n"
            usage_info += f"- æ°´å°: {'æ˜¯' if watermark else 'å¦'}\n"
            
            if usage:
                usage_info += f"- ç”Ÿæˆå›¾åƒç»Ÿè®¡: {usage.get('generated_images', 0)}\n"
                usage_info += f"- è¾“å‡ºToken: {usage.get('output_tokens', 0)}\n"
                usage_info += f"- æ€»è®¡Token: {usage.get('total_tokens', usage.get('output_tokens', 0))}"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] å›¾åƒç”Ÿæˆå®Œæˆ")
            print(f"[ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            raise ValueError(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "WanQingJiMeng40ImageToImage": WanQingJiMeng40ImageToImageNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanQingJiMeng40ImageToImage": "ä¸‡æ“å³æ¢¦4.0å›¾ç”Ÿå›¾"
}

import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class WanQingGPTImageGenerationNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc"], {
                    "default": "prod",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "prompt": ("STRING", {
                    "default": "ç”Ÿæˆä¸€ä¸ªå¸¦è´è¶ç»“çš„é²¸é±¼",
                    "multiline": True,
                    "tooltip": "å›¾åƒæè¿°æç¤ºè¯"
                }),
                "image_count": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡"
                }),
                "image_size": (["1024x1024", "1792x1024", "1024x1792", "auto"], {
                    "default": "1024x1024",
                    "tooltip": "å›¾åƒå°ºå¯¸"
                }),
                "quality": (["medium", "high", "low", "auto"], {
                    "default": "medium",
                    "tooltip": "å›¾åƒè´¨é‡"
                }),
                "output_format": (["png", "jpeg"], {
                    "default": "png",
                    "tooltip": "è¾“å‡ºæ ¼å¼"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "generate_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging-sgp.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod-sgp.corp.kuaishou.com", 
            "prod-old": "https://llm-gateway-prod.corp.kuaishou.com",
            "idc": "http://llm-gateway.internal"
        }

    def generate_image(self, environment, api_key, prompt, image_count, 
                      image_size, quality, output_format, timeout):
        """
        ä¸‡æ“ GPT å›¾åƒç”Ÿæˆ
        """
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key")
            
            if not prompt or prompt.strip() == "":
                raise ValueError("å›¾åƒæè¿°ä¸èƒ½ä¸ºç©º")

            # æ„å»ºURL
            base_url = self.environments[environment]
            url = f"{base_url}/llm-serve/v1/images/generations"
            
            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "prompt": prompt.strip(),
                "model": "gpt-image-1",
                "n": image_count,
                "size": image_size,
                "quality": quality,
                "output_format": output_format
            }
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "x-api-key": api_key.strip(),
                "Content-Type": "application/json",
                "User-Agent": "ComfyUI-WanQing-GPT/1.0"
            }
            
            print(f"[ä¸‡æ“ GPT] å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"[ä¸‡æ“ GPT] è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False, indent=2)}")
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=timeout
            )
            
            print(f"[ä¸‡æ“ GPT] å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                raise ValueError(f"æ— æ•ˆçš„JSONå“åº”: {response.text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'unknown_parameter' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå‚æ•°æ˜¯å¦æ­£ç¡®ï¼ŒæŸäº›å‚æ•°å¯èƒ½ä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ"
                elif 'invalid_value' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…"
                elif 'invalid_request_error' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå¿…éœ€å‚æ•°"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆï¼Œè”ç³» @äºæ·¼ è·å–æ­£ç¡®çš„ä¸‡æ“ç½‘å…³key"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                
                raise ValueError(f"APIé”™è¯¯ [{error_code}]: {error_msg}")
            
            # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
            images_tensor = []
            image_data = response_data.get('data', [])
            
            if not image_data:
                raise ValueError("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
            
            print(f"[ä¸‡æ“ GPT] æˆåŠŸç”Ÿæˆ {len(image_data)} å¼ å›¾åƒ")
            
            for idx, item in enumerate(image_data):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_bytes = base64.b64decode(b64_data)
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if image.mode != 'RGB':
                        image = image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[ä¸‡æ“ GPT] å›¾åƒ {idx + 1}: {image.size}, æ¨¡å¼: {image.mode}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    print(f"[ä¸‡æ“ GPT] æ”¶åˆ°å›¾åƒURL: {item['url']}")
                    # è¿™é‡Œå¯ä»¥é€‰æ‹©ä¸‹è½½URLå›¾åƒï¼Œæˆ–è€…åªæ˜¯è®°å½•URL
                    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡URLå½¢å¼çš„å›¾åƒ
                    print(f"[ä¸‡æ“ GPT] è­¦å‘Š: è·³è¿‡URLå½¢å¼çš„å›¾åƒï¼Œå½“å‰ç‰ˆæœ¬ä»…æ”¯æŒbase64æ ¼å¼")
            
            if not images_tensor:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®ï¼ˆä»…æ”¯æŒbase64æ ¼å¼ï¼‰")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage = response_data.get('usage', {})
            usage_info = f"Tokenä½¿ç”¨æƒ…å†µ:\n"
            usage_info += f"- è¾“å…¥Token: {usage.get('input_tokens', 0)}\n"
            usage_info += f"- è¾“å‡ºToken: {usage.get('output_tokens', 0)}\n"
            usage_info += f"- æ€»è®¡Token: {usage.get('input_tokens', 0) + usage.get('output_tokens', 0)}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[ä¸‡æ“ GPT] å›¾åƒç”Ÿæˆå®Œæˆ")
            print(f"[ä¸‡æ“ GPT] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            raise ValueError(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "WanQingGPTImageGeneration": WanQingGPTImageGenerationNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanQingGPTImageGeneration": "ä¸‡æ“ GPT å›¾åƒç”Ÿæˆ"
} 
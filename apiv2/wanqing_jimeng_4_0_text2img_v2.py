import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class WanQingJiMeng40TextToImageNodeV2:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc", "overseas", "domestic"], {
                    "default": "staging",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "prompt": ("STRING", {
                    "default": "æ˜Ÿé™…ç©¿è¶Šï¼Œé»‘æ´ï¼Œé»‘æ´é‡Œå†²å‡ºä¸€è¾†å¿«æ”¯ç¦»ç ´ç¢çš„å¤å¤åˆ—è½¦ï¼ŒæŠ¢è§†è§‰å†²å‡»åŠ›ï¼Œç”µå½±å¤§ç‰‡ï¼Œæœ«æ—¥æ—¢è§†æ„Ÿï¼ŒåŠ¨æ„Ÿï¼Œå¯¹æ¯”è‰²ï¼Œocæ¸²æŸ“ï¼Œå…‰çº¿è¿½è¸ªï¼ŒåŠ¨æ€æ¨¡ç³Šï¼Œæ™¯æ·±ï¼Œè¶…ç°å®ä¸»ä¹‰ï¼Œæ·±è“ï¼Œç”»é¢é€šè¿‡ç»†è…»çš„ä¸°å¯Œçš„è‰²å½©å±‚æ¬¡å¡‘é€ ä¸»ä½“ä¸åœºæ™¯ï¼Œè´¨æ„ŸçœŸå®ï¼Œæš—é»‘é£èƒŒæ™¯çš„å…‰å½±æ•ˆæœè¥é€ å‡ºæ°›å›´ï¼Œæ•´ä½“å…¼å…·è‰ºæœ¯å¹»æƒ³æ„Ÿï¼Œå¤¸å¼ çš„å¹¿è§’é€è§†æ•ˆæœï¼Œè€€å…‰ï¼Œåå°„ï¼Œæè‡´çš„å…‰å½±ï¼Œå¼ºå¼•åŠ›ï¼Œåå™¬",
                    "multiline": True,
                    "tooltip": "å›¾åƒæè¿°æç¤ºè¯ï¼Œå»ºè®®ç»“æ„ï¼šé£æ ¼å…³é”®è¯ + ä¸»è¦ç¾å­¦å…³é”®è¯ + è§†è§‰å†…å®¹ + è§†è§‰ä¸Šä¸‹æ–‡ + è¡¥å……ç¾å­¦å…³é”®è¯"
                }),
                "size": (["4K", "2K", "1K", "1024x1024", "1024x1536", "1536x1024"], {
                    "default": "2K",
                    "tooltip": "å›¾åƒå°ºå¯¸ï¼ˆ4Kæ”¯æŒè¶…é«˜æ¸…è¾“å‡ºï¼‰"
                }),
                "response_format": (["url", "b64_json"], {
                    "default": "url",
                    "tooltip": "å“åº”æ ¼å¼"
                }),
                "sequential_image_generation": (["enabled", "disabled"], {
                    "default": "disabled",
                    "tooltip": "é¡ºåºå›¾åƒç”Ÿæˆ"
                }),
                "stream": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æµå¼å“åº”"
                }),
                "watermark": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "use_proxy": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦ä½¿ç”¨ä»£ç†æœåŠ¡å™¨"
                }),
                "image_download_proxy": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å›¾ç‰‡ä¸‹è½½æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆçº¿ä¸Šç¯å¢ƒè®¿é—®å¤–éƒ¨å›¾ç‰‡URLå¯èƒ½éœ€è¦å¯ç”¨ï¼‰"
                }),
                "image_proxy_url": ("STRING", {
                    "default": "http://http://10.20.254.26:11080",
                    "tooltip": "å›¾ç‰‡ä¸‹è½½ä»£ç†æœåŠ¡å™¨åœ°å€"
                }),
                "custom_base_url": ("STRING", {
                    "default": "",
                    "tooltip": "è‡ªå®šä¹‰APIåŸºç¡€URLï¼ˆä¼˜å…ˆçº§é«˜äºç¯å¢ƒé€‰æ‹©ï¼‰"
                }),
                "custom_endpoint": ("STRING", {
                    "default": "/llm-serve/v1/images/generations",
                    "tooltip": "è‡ªå®šä¹‰APIç«¯ç‚¹è·¯å¾„"
                })
            },
            "optional": {
                "n": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡ï¼ˆ1-4å¼ ï¼‰"
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "step": 1,
                    "tooltip": "éšæœºç§å­ï¼Œ-1ä¸ºéšæœºç”Ÿæˆ"
                }),
                "negative_prompt": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "tooltip": "è´Ÿé¢æç¤ºè¯ï¼Œæè¿°ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹"
                }),
                "quality": (["hd", "standard"], {
                    "default": "hd",
                    "tooltip": "å›¾åƒè´¨é‡ï¼šhdï¼ˆé«˜æ¸…ï¼‰æˆ– standardï¼ˆæ ‡å‡†ï¼‰"
                }),
                "style": (["natural", "vivid"], {
                    "default": "vivid",
                    "tooltip": "å›¾åƒé£æ ¼ï¼šnaturalï¼ˆè‡ªç„¶ï¼‰æˆ– vividï¼ˆç”ŸåŠ¨ï¼‰"
                }),
                "guidance_scale": ("FLOAT", {
                    "default": 7.5,
                    "min": 1.0,
                    "max": 20.0,
                    "step": 0.5,
                    "tooltip": "å¼•å¯¼å¼ºåº¦ï¼Œæ§åˆ¶ç”Ÿæˆå›¾åƒä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦"
                }),
                "steps": ("INT", {
                    "default": 50,
                    "min": 10,
                    "max": 100,
                    "step": 1,
                    "tooltip": "æ¨ç†æ­¥æ•°ï¼Œæ›´å¤šæ­¥æ•°é€šå¸¸å¾—åˆ°æ›´é«˜è´¨é‡å›¾åƒ"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "BOOLEAN", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("images", "success", "message", "response_json", "usage_info")
    FUNCTION = "generate_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api-v2"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod.corp.kuaishou.com", 
            "idc": "http://llm-gateway.internal",
            "overseas": "http://llm-gateway-sgp.internal",
            "domestic": "http://llm-gateway.internal"
        }
        self.execution_logs = []
    
    def _log(self, message, level="INFO"):
        """ç»Ÿä¸€çš„æ—¥å¿—è®°å½•æ–¹æ³•"""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        self.execution_logs.append(log_entry)
    
    def _get_execution_log(self):
        """è·å–å®Œæ•´çš„æ‰§è¡Œæ—¥å¿—"""
        return "\n".join(self.execution_logs)
    
    def _clear_logs(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.execution_logs = []
    
    def _print_and_format_logs(self):
        """æ‰“å°å¹¶æ ¼å¼åŒ–æ—¥å¿—è¾“å‡º"""
        log_output = self._get_execution_log()
        print("\n" + "="*80)
        print("ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ æ‰§è¡Œæ—¥å¿—:")
        print("="*80)
        print(log_output)
        print("="*80 + "\n")
        return log_output

    def _create_blank_image(self, width=512, height=512):
        """åˆ›å»ºç©ºç™½å›¾ç‰‡tensor"""
        # åˆ›å»ºç™½è‰²èƒŒæ™¯å›¾ç‰‡
        blank_array = np.ones((1, height, width, 3), dtype=np.float32)
        return torch.from_numpy(blank_array)

    def generate_image(self, environment, api_key, prompt, size, response_format, 
                      sequential_image_generation, stream, watermark, timeout, use_proxy, 
                      image_download_proxy, image_proxy_url, custom_base_url="", custom_endpoint="/llm-serve/v1/images/generations",
                      n=1, seed=-1, negative_prompt="", quality="hd", style="vivid", 
                      guidance_scale=7.5, steps=50):
        """
        ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ - æ”¯æŒ4Kè¶…é«˜æ¸…ã€å¤šå›¾ç”Ÿæˆã€é£æ ¼æ§åˆ¶ç­‰é«˜çº§åŠŸèƒ½
        
        æ”¯æŒçš„åŠŸèƒ½:
        - 4Kè¶…é«˜æ¸…å›¾åƒç”Ÿæˆ
        - å¤šå›¾åƒç”Ÿæˆ (1-4å¼ )
        - å¯é‡å¤ç»“æœ (ç§å­æ§åˆ¶)
        - è´Ÿé¢æç¤ºè¯è¿‡æ»¤
        - è´¨é‡å’Œé£æ ¼æ§åˆ¶
        - ç²¾ç»†çš„å¼•å¯¼å‚æ•°è°ƒèŠ‚
        """
        # æ¸…ç©ºå¹¶åˆå§‹åŒ–æ—¥å¿—
        self._clear_logs()
        self._log("å¼€å§‹å›¾åƒç”Ÿæˆä»»åŠ¡")
        
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            self._log("å¼€å§‹å‚æ•°éªŒè¯")
            if not api_key or api_key.strip() == "":
                self._log("å‚æ•°éªŒè¯å¤±è´¥: API Keyä¸ºç©º", "ERROR")
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                error_msg = "API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key"
                return (blank_image, False, error_msg, "", log_output)
            
            if not prompt or prompt.strip() == "":
                self._log("å‚æ•°éªŒè¯å¤±è´¥: å›¾åƒæè¿°ä¸ºç©º", "ERROR")
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                error_msg = "å›¾åƒæè¿°ä¸èƒ½ä¸ºç©º"
                return (blank_image, False, error_msg, "", log_output)
            
            self._log("å‚æ•°éªŒè¯é€šè¿‡")

            # æ„å»ºURL - ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„base_url
            if custom_base_url and custom_base_url.strip():
                base_url = custom_base_url.strip().rstrip('/')
                self._log(f"ä½¿ç”¨è‡ªå®šä¹‰base_url: {base_url}")
            else:
                base_url = self.environments[environment]
                self._log(f"ä½¿ç”¨ç¯å¢ƒé…ç½®: {environment} -> {base_url}")
            
            # ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹è·¯å¾„
            endpoint = custom_endpoint.strip() if custom_endpoint.strip() else "/llm-serve/v1/images/generations"
            endpoint = endpoint.lstrip('/')  # ç§»é™¤å¼€å¤´çš„æ–œæ 
            url = f"{base_url}/{endpoint}"
            self._log(f"å®Œæ•´APIåœ°å€: {url}")
            
            # æ„å»ºè¯·æ±‚ä½“
            self._log("æ„å»ºè¯·æ±‚ä½“")
            payload = {
                "model": "doubao-seedream-4-0-250828",
                "prompt": prompt.strip(),
                "size": size,
                "sequential_image_generation": sequential_image_generation,
                "stream": stream,
                "response_format": response_format,
                "watermark": watermark
            }
            
            # æ·»åŠ å›¾åƒæ•°é‡
            if n > 1:
                payload["n"] = n
                
            # æ·»åŠ éšæœºç§å­
            if seed != -1:
                payload["seed"] = seed
                
            # æ·»åŠ è´Ÿé¢æç¤ºè¯
            if negative_prompt and negative_prompt.strip():
                payload["negative_prompt"] = negative_prompt.strip()
                
            # æ·»åŠ è´¨é‡è®¾ç½®
            if quality != "hd":
                payload["quality"] = quality
                
            # æ·»åŠ é£æ ¼è®¾ç½®
            if style != "vivid":
                payload["style"] = style
                
            # æ·»åŠ å¼•å¯¼å¼ºåº¦
            if guidance_scale != 7.5:
                payload["guidance_scale"] = guidance_scale
                
            # æ·»åŠ æ¨ç†æ­¥æ•°
            if steps != 50:
                payload["steps"] = steps
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "x-api-key": api_key.strip(),
                "Content-Type": "application/json",
                "User-Agent": "ComfyUI-JiMeng-4.0-T2I/1.0"
            }
            
            # è®°å½•è¯·æ±‚ä¿¡æ¯
            self._log(f"å‘é€è¯·æ±‚åˆ°: {url}")
            self._log(f"æç¤ºè¯: {prompt.strip()[:100]}{'...' if len(prompt.strip()) > 100 else ''}")
            self._log(f"å°ºå¯¸: {size}, ç”Ÿæˆæ•°é‡: {n}")
            
            if seed != -1:
                self._log(f"éšæœºç§å­: {seed}")
            if negative_prompt and negative_prompt.strip():
                self._log(f"è´Ÿé¢æç¤ºè¯: {negative_prompt.strip()[:50]}{'...' if len(negative_prompt.strip()) > 50 else ''}")
            if quality != "hd":
                self._log(f"å›¾åƒè´¨é‡: {quality}")
            if style != "vivid":
                self._log(f"å›¾åƒé£æ ¼: {style}")
            if guidance_scale != 7.5:
                self._log(f"å¼•å¯¼å¼ºåº¦: {guidance_scale}")
            if steps != 50:
                self._log(f"æ¨ç†æ­¥æ•°: {steps}")
            
            self._log(f"æ°´å°: {'å¯ç”¨' if watermark else 'ç¦ç”¨'}, æµå¼å“åº”: {'å¯ç”¨' if stream else 'ç¦ç”¨'}")
            self._log(f"è¶…æ—¶è®¾ç½®: {timeout}ç§’")
            
            # é…ç½®ä»£ç†
            request_kwargs = {
                "headers": headers,
                "json": payload,
                "timeout": timeout
            }
            if use_proxy:
                request_kwargs["proxies"] = {"http": None, "https": None}
                self._log("APIè¯·æ±‚ä»£ç†: ç¦ç”¨ç³»ç»Ÿä»£ç†")
            else:
                self._log("APIè¯·æ±‚ä»£ç†: ä½¿ç”¨ç³»ç»Ÿä»£ç†")
            
            # å‘é€è¯·æ±‚
            self._log("å‘é€APIè¯·æ±‚...")
            response = requests.post(url, **request_kwargs)
            
            self._log(f"æ”¶åˆ°å“åº”, çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            self._log("è§£æå“åº”JSON")
            try:
                response_data = response.json()
                self._log("å“åº”JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                self._log(f"JSONè§£æå¤±è´¥: {str(e)}", "ERROR")
                self._log(f"å“åº”å†…å®¹: {response.text[:200]}", "ERROR")
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                response_text = response.text if response.text else "ç©ºå“åº”"
                response_text = response_text[:1000] + "..." if len(response_text) > 1000 else response_text
                error_msg = f"æ— æ•ˆçš„JSONå“åº”:\n"
                error_msg += f"- çŠ¶æ€ç : {response.status_code}\n"
                error_msg += f"- å“åº”å†…å®¹: {response_text}"
                return (blank_image, False, error_msg, "", log_output)
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                self._log(f"APIè¿”å›é”™è¯¯: {error_msg}", "ERROR")
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'unknown_parameter' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå‚æ•°æ˜¯å¦æ­£ç¡®ï¼ŒæŸäº›å‚æ•°å¯èƒ½ä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ"
                elif 'invalid_value' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…"
                elif 'invalid_request_error' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå¿…éœ€å‚æ•°"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆï¼Œè”ç³» @äºæ·¼ è·å–æ­£ç¡®çš„ä¸‡æ“ç½‘å…³key"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                full_error_msg = f"APIé”™è¯¯ [{error_code}]: {error_msg}"
                return (blank_image, False, full_error_msg, "", log_output)
            
            # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
            self._log("å¼€å§‹å¤„ç†ç”Ÿæˆçš„å›¾åƒ")
            images_tensor = []
            image_data = response_data.get('data', [])
            
            if not image_data:
                self._log("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®", "ERROR")
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                error_msg = "å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®"
                return (blank_image, False, error_msg, "", log_output)
            
            self._log(f"æ”¶åˆ° {len(image_data)} ä¸ªå›¾åƒæ•°æ®")
            
            for idx, item in enumerate(image_data):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_size = item.get('size', 'æœªçŸ¥')
                    
                    image_bytes = base64.b64decode(b64_data)
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if image.mode != 'RGB':
                        image = image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    self._log(f"å›¾åƒ {idx + 1}: {image.size}, æ¨¡å¼: {image.mode}, å°ºå¯¸: {image_size}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    image_url = item['url']
                    image_size = item.get('size', 'æœªçŸ¥')
                    self._log(f"æ”¶åˆ°å›¾åƒURL: {image_url[:80]}..., å°ºå¯¸: {image_size}")
                    
                    try:
                        # é…ç½®å›¾ç‰‡ä¸‹è½½ä»£ç†è®¾ç½®
                        download_kwargs = {"timeout": 60}
                        if image_download_proxy:
                            # ä½¿ç”¨æŒ‡å®šçš„ä»£ç†æœåŠ¡å™¨
                            self._log(f"å›¾ç‰‡ä¸‹è½½ä»£ç†: ä½¿ç”¨ {image_proxy_url}")
                            download_kwargs["proxies"] = {
                                "http": image_proxy_url,
                                "https": image_proxy_url
                            }
                        else:
                            # ç¦ç”¨ä»£ç†ï¼ˆç”¨äºå†…éƒ¨ç½‘ç»œæˆ–ç›´è¿ï¼‰
                            self._log("å›¾ç‰‡ä¸‹è½½ä»£ç†: ç¦ç”¨")
                            download_kwargs["proxies"] = {"http": None, "https": None}
                        
                        img_response = requests.get(image_url, **download_kwargs)
                        img_response.raise_for_status()
                        image = Image.open(io.BytesIO(img_response.content))
                        
                        # è½¬æ¢ä¸ºRGB
                        if image.mode != 'RGB':
                            image = image.convert('RGB')
                        
                        # è½¬æ¢ä¸ºtensor
                        image_np = np.array(image).astype(np.float32) / 255.0
                        image_tensor = torch.from_numpy(image_np)[None,]
                        images_tensor.append(image_tensor)
                        
                        self._log(f"ä¸‹è½½å›¾åƒ {idx + 1}: å®é™…å°ºå¯¸{image.size}, æ¨¡å¼: {image.mode}")
                        
                    except Exception as e:
                        self._log(f"ä¸‹è½½å›¾åƒ {idx + 1} å¤±è´¥: {str(e)}", "ERROR")
                        continue
            
            if not images_tensor:
                self._log("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®", "ERROR")
                log_output = self._print_and_format_logs()
                blank_image = self._create_blank_image()
                error_msg = "æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®"
                return (blank_image, False, error_msg, "", log_output)
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            self._log(f"æˆåŠŸå¤„ç† {len(images_tensor)} å¼ å›¾åƒ")
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage = response_data.get('usage', {})
            usage_info = f"ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ç»“æœ:\n"
            usage_info += f"- æ¨¡å‹: doubao-seedream-4-0-250828\n"
            usage_info += f"- è¯·æ±‚å°ºå¯¸: {size}\n"
            
            # æ˜¾ç¤ºå®é™…ç”Ÿæˆçš„å›¾åƒå°ºå¯¸
            actual_sizes = []
            for item in image_data:
                if 'size' in item:
                    actual_sizes.append(item['size'])
            if actual_sizes:
                usage_info += f"- å®é™…å°ºå¯¸: {', '.join(actual_sizes)}\n"
            
            usage_info += f"- å“åº”æ ¼å¼: {response_format}\n"
            usage_info += f"- è¯·æ±‚å›¾åƒæ•°é‡: {n}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}\n"
            
            if seed != -1:
                usage_info += f"- éšæœºç§å­: {seed}\n"
            if negative_prompt and negative_prompt.strip():
                usage_info += f"- è´Ÿé¢æç¤ºè¯: {negative_prompt.strip()[:50]}{'...' if len(negative_prompt.strip()) > 50 else ''}\n"
            if quality != "hd":
                usage_info += f"- å›¾åƒè´¨é‡: {quality}\n"
            if style != "vivid":
                usage_info += f"- å›¾åƒé£æ ¼: {style}\n"
            if guidance_scale != 7.5:
                usage_info += f"- å¼•å¯¼å¼ºåº¦: {guidance_scale}\n"
            if steps != 50:
                usage_info += f"- æ¨ç†æ­¥æ•°: {steps}\n"
                
            usage_info += f"- é¡ºåºç”Ÿæˆ: {sequential_image_generation}\n"
            usage_info += f"- æµå¼å“åº”: {'æ˜¯' if stream else 'å¦'}\n"
            usage_info += f"- æ°´å°: {'æ˜¯' if watermark else 'å¦'}\n"
            
            if usage:
                usage_info += f"- ç”Ÿæˆå›¾åƒç»Ÿè®¡: {usage.get('generated_images', 0)}\n"
                usage_info += f"- è¾“å‡ºToken: {usage.get('output_tokens', 0)}\n"
                usage_info += f"- æ€»è®¡Token: {usage.get('total_tokens', usage.get('output_tokens', 0))}"
            
            # è®°å½•APIä½¿ç”¨ä¿¡æ¯
            self._log(f"APIä½¿ç”¨ä¿¡æ¯: {usage_info.replace(chr(10), ' | ')}")
            self._log("å›¾åƒç”Ÿæˆä»»åŠ¡å®Œæˆ", "SUCCESS")
            
            # æ‰“å°å¹¶è·å–æ‰§è¡Œæ—¥å¿—
            log_output = self._print_and_format_logs()
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            # æ„å»ºæˆåŠŸæ¶ˆæ¯
            success_message = "å›¾åƒç”ŸæˆæˆåŠŸ"
            
            return (result_images, True, success_message, response_json, log_output)
            
        except requests.exceptions.Timeout:
            self._log(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰", "ERROR")
            log_output = self._print_and_format_logs()
            blank_image = self._create_blank_image()
            error_msg = f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚"
            return (blank_image, False, error_msg, "", log_output)
        except requests.exceptions.ConnectionError as e:
            self._log(f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}", "ERROR")
            log_output = self._print_and_format_logs()
            blank_image = self._create_blank_image()
            error_msg = f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®"
            return (blank_image, False, error_msg, "", log_output)
        except requests.exceptions.RequestException as e:
            self._log(f"è¯·æ±‚å¼‚å¸¸: {str(e)}", "ERROR")
            log_output = self._print_and_format_logs()
            blank_image = self._create_blank_image()
            error_msg = f"è¯·æ±‚å¤±è´¥: {str(e)}"
            return (blank_image, False, error_msg, "", log_output)
        except Exception as e:
            self._log(f"æœªçŸ¥å¼‚å¸¸: {str(e)}", "ERROR")
            import traceback
            self._log(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}", "ERROR")
            log_output = self._print_and_format_logs()
            blank_image = self._create_blank_image()
            error_msg = f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}"
            return (blank_image, False, error_msg, "", log_output)

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "WanQingJiMeng40TextToImageV2": WanQingJiMeng40TextToImageNodeV2
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanQingJiMeng40TextToImageV2": "ä¸‡æ“å³æ¢¦4.0æ–‡ç”Ÿå›¾ V2"
}

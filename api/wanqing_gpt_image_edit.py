import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class WanQingGPTImageEditNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc"], {
                    "default": "prod",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "image": ("IMAGE", {
                    "tooltip": "å¾…ç¼–è¾‘çš„åŸå§‹å›¾åƒ"
                }),
                "prompt": ("STRING", {
                    "default": "åˆ›å»ºè“å¤©",
                    "multiline": True,
                    "tooltip": "ç¼–è¾‘æè¿°æç¤ºè¯"
                }),
                "image_count": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾åƒæ•°é‡"
                }),
                "image_size": (["1024x1024", "1024x1536", "1536x1024", "auto"], {
                    "default": "1024x1024",
                    "tooltip": "è¾“å‡ºå›¾åƒå°ºå¯¸"
                }),
                "quality": (["medium", "high", "low", "auto"], {
                    "default": "high",
                    "tooltip": "å›¾åƒè´¨é‡"
                }),
                "output_format": (["png", "jpeg"], {
                    "default": "png",
                    "tooltip": "è¾“å‡ºæ ¼å¼"
                }),
                "max_file_size_mb": ("FLOAT", {
                    "default": 4.0,
                    "min": 1.0,
                    "max": 10.0,
                    "step": 0.5,
                    "tooltip": "å›¾ç‰‡å‹ç¼©çš„æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé¿å…Payload Too Largeé”™è¯¯"
                }),
                "timeout": ("FLOAT", {
                    "default": 120.0,
                    "min": 30.0,
                    "max": 300.0,
                    "step": 10.0,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                })
            },
            "optional": {
                "mask": ("MASK", {
                    "tooltip": "ç¼–è¾‘é®ç½©ï¼ˆå¯é€‰ï¼‰ã€‚ç™½è‰²åŒºåŸŸè¡¨ç¤ºè¦ç¼–è¾‘çš„éƒ¨åˆ†ï¼Œä¸æä¾›åˆ™ç¼–è¾‘æ•´ä¸ªå›¾åƒ"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "edit_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging-sgp.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod-sgp.corp.kuaishou.com", 
            "prod-old": "https://llm-gateway-prod.corp.kuaishou.com",
            "idc": "http://llm-gateway.internal"
        }

    def tensor_to_pil(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
        # å¤„ç†batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor[0]
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        np_image = tensor.cpu().numpy()
        if np_image.max() <= 1.0:
            np_image = (np_image * 255).astype(np.uint8)
        else:
            np_image = np.clip(np_image, 0, 255).astype(np.uint8)
        
        return Image.fromarray(np_image)

    def mask_to_pil(self, mask_tensor, target_size=None):
        """å°†MASK tensorè½¬æ¢ä¸ºPILå›¾åƒï¼ˆå¸¦alphaé€šé“çš„PNGæ ¼å¼ï¼‰"""
        # å¤„ç†batchç»´åº¦
        if len(mask_tensor.shape) == 3:
            mask_tensor = mask_tensor[0]  # å–ç¬¬ä¸€ä¸ªbatch
        elif len(mask_tensor.shape) == 4:
            mask_tensor = mask_tensor[0, 0]  # å–ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªé€šé“
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        mask_np = mask_tensor.cpu().numpy()
        if mask_np.max() <= 1.0:
            mask_np = (mask_np * 255).astype(np.uint8)
        else:
            mask_np = np.clip(mask_np, 0, 255).astype(np.uint8)
        
        # åˆ›å»ºPILå›¾åƒä»maskæ•°æ®
        height, width = mask_np.shape
        mask_pil = Image.fromarray(mask_np, mode='L')
        
        # å¦‚æœæä¾›äº†ç›®æ ‡å°ºå¯¸ï¼Œè°ƒæ•´é®ç½©å°ºå¯¸ä»¥åŒ¹é…åŸå§‹å›¾åƒ
        if target_size is not None and (width, height) != target_size:
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è°ƒæ•´é®ç½©å°ºå¯¸ä» {(width, height)} åˆ° {target_size}")
            mask_pil = mask_pil.resize(target_size, Image.Resampling.LANCZOS)
        
        # åˆ›å»ºRGBAå›¾åƒï¼Œä½¿ç”¨maskä½œä¸ºalphaé€šé“
        # ç™½è‰²åŒºåŸŸï¼ˆmaskå€¼ä¸º255ï¼‰è¡¨ç¤ºè¦ç¼–è¾‘çš„åŒºåŸŸ
        rgba_image = Image.new('RGBA', mask_pil.size, (255, 255, 255, 255))
        
        # å°†maskè®¾ç½®ä¸ºalphaé€šé“
        rgba_image.putalpha(mask_pil)
        
        return rgba_image

    def compress_image(self, image, max_size_mb=4.0, format="JPEG", quality=85, target_size=None):
        """å‹ç¼©å›¾åƒåˆ°æŒ‡å®šå¤§å°ä»¥ä¸‹ï¼Œå¯é€‰ä¿æŒç›®æ ‡å°ºå¯¸"""
        max_size_bytes = int(max_size_mb * 1024 * 1024)
        
        # å¦‚æœæ˜¯é®ç½©å›¾åƒï¼ˆå¯èƒ½éœ€è¦alphaé€šé“ï¼‰ï¼Œä¿æŒPNGæ ¼å¼
        if format == "PNG" and image.mode in ['RGBA', 'LA']:
            # å¯¹äºPNGé®ç½©ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„å‹ç¼©ç­–ç•¥
            current_quality = 9  # PNGå‹ç¼©çº§åˆ« (0-9, 9ä¸ºæœ€é«˜å‹ç¼©)
            
            # å…ˆå°è¯•ä¸ç¼©å°å°ºå¯¸ï¼Œåªè°ƒæ•´å‹ç¼©çº§åˆ«
            original_size = image.size
            scale_factor = 1.0
            
            while True:
                buffer = io.BytesIO()
                temp_image = image.copy()
                
                # å¦‚æœéœ€è¦ä¿æŒç›®æ ‡å°ºå¯¸ï¼ˆå¦‚é®ç½©å›¾åƒï¼‰ï¼Œå³ä½¿å‹ç¼©åä¹Ÿè¦è°ƒæ•´å›ç›®æ ‡å°ºå¯¸
                if target_size is not None and temp_image.size != target_size:
                    temp_image = temp_image.resize(target_size, Image.Resampling.LANCZOS)
                elif scale_factor < 1.0:
                    # åªæœ‰åœ¨æ²¡æœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶æ—¶æ‰ç¼©å°å›¾åƒ
                    new_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))
                    temp_image = temp_image.resize(new_size, Image.Resampling.LANCZOS)
                
                temp_image.save(buffer, format="PNG", optimize=True, compress_level=current_quality)
                
                if buffer.tell() <= max_size_bytes or (target_size is None and scale_factor <= 0.3):
                    buffer.seek(0)
                    final_size = temp_image.size
                    return buffer.getvalue(), final_size
                
                # å¦‚æœæœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶ï¼Œä¼˜å…ˆé™ä½å‹ç¼©è´¨é‡è€Œä¸æ˜¯ç¼©å°å°ºå¯¸
                if target_size is not None:
                    if current_quality > 0:
                        current_quality = max(0, current_quality - 1)
                    else:
                        # è´¨é‡å·²ç»åˆ°æœ€ä½ï¼Œæ¥å—å½“å‰ç»“æœ
                        buffer.seek(0)
                        final_size = temp_image.size
                        return buffer.getvalue(), final_size
                else:
                    scale_factor *= 0.8
        else:
            # å¯¹äºJPEGæ ¼å¼çš„æ™®é€šå›¾åƒ
            current_quality = quality
            scale_factor = 1.0
            original_size = image.size
            
            # ç¡®ä¿æ˜¯RGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            while current_quality >= 20:
                buffer = io.BytesIO()
                temp_image = image.copy()
                
                # å¦‚æœéœ€è¦ä¿æŒç›®æ ‡å°ºå¯¸ï¼Œè°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
                if target_size is not None and temp_image.size != target_size:
                    temp_image = temp_image.resize(target_size, Image.Resampling.LANCZOS)
                elif current_quality == 20 and scale_factor > 0.3:
                    # åªæœ‰åœ¨æ²¡æœ‰ç›®æ ‡å°ºå¯¸é™åˆ¶æ—¶æ‰ç¼©å°å›¾åƒ
                    scale_factor *= 0.8
                    new_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))
                    temp_image = temp_image.resize(new_size, Image.Resampling.LANCZOS)
                    current_quality = quality  # é‡ç½®è´¨é‡
                
                temp_image.save(buffer, format="JPEG", quality=current_quality, optimize=True)
                
                if buffer.tell() <= max_size_bytes:
                    buffer.seek(0)
                    final_size = temp_image.size
                    return buffer.getvalue(), final_size
                
                current_quality -= 10
        
        # å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œè¿”å›æœ€åçš„ç»“æœ
        buffer.seek(0)
        final_size = temp_image.size
        return buffer.getvalue(), final_size

    def edit_image(self, environment, api_key, image, prompt, 
                   image_count, image_size, quality, output_format, max_file_size_mb, timeout, mask=None):
        """
        ä¸‡æ“ GPT å›¾åƒç¼–è¾‘
        """
        # ç”¨äºè°ƒè¯•çš„è¯·æ±‚ä¿¡æ¯
        debug_info = {
            "url": "",
            "headers": {},
            "files_info": {},
            "request_size": 0,
            "error": None,
            "response_status": None,
            "response_content": ""
        }
        
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                debug_info["error"] = "API KeyéªŒè¯å¤±è´¥"
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key")
            
            if not prompt or prompt.strip() == "":
                debug_info["error"] = "ç¼–è¾‘æè¿°éªŒè¯å¤±è´¥"
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è°ƒè¯•ä¿¡æ¯: {debug_info}")
                raise ValueError("ç¼–è¾‘æè¿°ä¸èƒ½ä¸ºç©º")

            # å¤„ç†å›¾åƒå°ºå¯¸
            final_image_size = image_size
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ä½¿ç”¨å°ºå¯¸: {final_image_size}")

            # è½¬æ¢è¾“å…¥å›¾åƒ
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å¼€å§‹å¤„ç†è¾“å…¥å›¾åƒ...")
            
            # è½¬æ¢åŸå§‹å›¾åƒä¸ºPIL
            input_image = self.tensor_to_pil(image)
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] åŸå§‹å›¾åƒå°ºå¯¸: {input_image.size}, æ¨¡å¼: {input_image.mode}")
            
            # è½¬æ¢é®ç½©å›¾åƒä¸ºPILå¹¶ç¡®ä¿æœ‰alphaé€šé“
            mask_image = self.mask_to_pil(mask, input_image.size) if mask is not None else None
            if mask_image is not None:
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é®ç½©å›¾åƒå°ºå¯¸: {mask_image.size}, æ¨¡å¼: {mask_image.mode}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å¤„ç†åé®ç½©å›¾åƒæ¨¡å¼: {mask_image.mode}")
                # éªŒè¯å°ºå¯¸æ˜¯å¦åŒ¹é…
                if mask_image.size != input_image.size:
                    print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è­¦å‘Š: é®ç½©å°ºå¯¸ {mask_image.size} ä¸åŸå§‹å›¾åƒå°ºå¯¸ {input_image.size} ä¸åŒ¹é…")
                else:
                    print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ç¡®è®¤: é®ç½©å°ºå¯¸ä¸åŸå§‹å›¾åƒå°ºå¯¸åŒ¹é… {input_image.size}")
            else:
                print("[ä¸‡æ“ GPT ç¼–è¾‘] æœªæä¾›é®ç½©å›¾åƒï¼Œå°†ç¼–è¾‘æ•´ä¸ªåŸå§‹å›¾åƒ")

            # å‹ç¼©å›¾åƒä»¥é¿å…Payload Too Largeé”™è¯¯
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å‹ç¼©å›¾åƒï¼Œæœ€å¤§å¤§å°: {max_file_size_mb}MB")
            
            # å‹ç¼©åŸå§‹å›¾åƒ
            image_data, compressed_size = self.compress_image(
                input_image, 
                max_size_mb=max_file_size_mb * 0.6,  # ç»™åŸå§‹å›¾åƒåˆ†é…60%çš„ç©ºé—´
                format="JPEG",
                quality=85
            )
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] åŸå§‹å›¾åƒå‹ç¼©åå¤§å°: {len(image_data) / 1024:.1f}KB, å°ºå¯¸: {compressed_size}")
            
            # å‹ç¼©é®ç½©å›¾åƒ
            mask_data = None
            mask_compressed_size = None
            if mask_image is not None:
                mask_data, mask_compressed_size = self.compress_image(
                    mask_image,
                    max_size_mb=max_file_size_mb * 0.4,  # ç»™é®ç½©å›¾åƒåˆ†é…40%çš„ç©ºé—´
                    format="PNG",  # é®ç½©å¿…é¡»æ˜¯PNGä»¥ä¿æŒalphaé€šé“
                    target_size=input_image.size  # ç¡®ä¿å‹ç¼©åçš„é®ç½©å°ºå¯¸ä¸åŸå§‹å›¾åƒä¸€è‡´
                )
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é®ç½©å›¾åƒå‹ç¼©åå¤§å°: {len(mask_data) / 1024:.1f}KB, å°ºå¯¸: {mask_compressed_size}")
            else:
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è·³è¿‡é®ç½©å›¾åƒå‹ç¼©ï¼ˆæœªæä¾›é®ç½©ï¼‰")

            # æ„å»ºURL
            base_url = self.environments[environment]
            url = f"{base_url}/llm-serve/v1/images/edit"
            debug_info["url"] = url
            
            # æ„å»ºmultipart/form-dataè¯·æ±‚
            files = {
                'image': ('image.jpg', image_data, 'image/jpeg'),
                'prompt': (None, prompt.strip()),
                'model': (None, 'gpt-image-1'),
                'n': (None, str(image_count)),
                'size': (None, final_image_size),
                'quality': (None, quality),
                'output_format': (None, output_format)
            }

            if mask_data is not None:
                files['mask'] = ('mask.png', mask_data, 'image/png')
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "x-api-key": api_key.strip(),
                "User-Agent": "ComfyUI-WanQing-GPT-Edit/1.0"
            }
            debug_info["headers"] = {k: v if k != "x-api-key" else "***éšè—***" for k, v in headers.items()}
            
            # è®°å½•æ–‡ä»¶ä¿¡æ¯ç”¨äºè°ƒè¯•
            debug_info["files_info"] = {
                'image': {
                    'filename': 'image.jpg',
                    'size_kb': len(image_data) / 1024,
                    'content_type': 'image/jpeg'
                },
                'prompt': prompt.strip(),
                'model': 'gpt-image-1',
                'n': str(image_count),
                'size': final_image_size,
                'quality': quality,
                'output_format': output_format
            }
            
            if mask_data is not None:
                debug_info["files_info"]['mask'] = {
                    'filename': 'mask.png',
                    'size_kb': len(mask_data) / 1024,
                    'content_type': 'image/png'
                }
            
            total_request_size = len(image_data) + (len(mask_data) if mask_data is not None else 0)
            debug_info["request_size"] = total_request_size / 1024  # KB
            
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å‚æ•°:")
            print(f"  - prompt: {prompt.strip()}")
            print(f"  - model: gpt-image-1")
            print(f"  - n: {image_count}")
            print(f"  - size: {final_image_size}")
            print(f"  - quality: {quality}")
            print(f"  - output_format: {output_format}")
            print(f"  - åŸå§‹å›¾åƒ: {len(image_data) / 1024:.1f}KB")
            if mask_data is not None:
                print(f"  - é®ç½©å›¾åƒ: {len(mask_data) / 1024:.1f}KB")
            print(f"  - æ€»è¯·æ±‚å¤§å°: {total_request_size / 1024:.1f}KB")
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                url,
                headers=headers,
                files=files,
                timeout=timeout
            )
            
            debug_info["response_status"] = response.status_code
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {response.status_code}")
            
            # è§£æå“åº”
            try:
                response_data = response.json()
                debug_info["response_content"] = json.dumps(response_data, ensure_ascii=False, indent=2)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
                response_text = response.text if response.text else "ç©ºå“åº”"
                debug_info["response_content"] = response_text
                debug_info["error"] = f"JSONè§£æå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”å†…å®¹: {response_text}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
                
                if response.status_code == 404:
                    raise ValueError(f"APIç«¯ç‚¹ä¸å­˜åœ¨ (404): {url}\nå“åº”å†…å®¹: {response_text}\n\nğŸ’¡ å»ºè®®: \n1. æ£€æŸ¥APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®\n2. ç¡®è®¤å›¾åƒç¼–è¾‘åŠŸèƒ½æ˜¯å¦å·²åœ¨æ­¤ç¯å¢ƒä¸­å¯ç”¨\n3. è”ç³» @äºæ·¼ ç¡®è®¤æ­£ç¡®çš„APIç«¯ç‚¹")
                else:
                    raise ValueError(f"æ— æ•ˆçš„JSONå“åº” (çŠ¶æ€ç : {response.status_code}): {response_text}")
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if not response.ok:
                error_msg = response_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                error_type = response_data.get('error', {}).get('type', 'unknown_error')
                error_code = response_data.get('error', {}).get('code', 'unknown')
                
                debug_info["error"] = f"APIé”™è¯¯ [{error_code}]: {error_msg} (ç±»å‹: {error_type})"
                
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
                
                # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                if 'payload too large' in error_msg.lower() or response.status_code == 413:
                    error_msg += f"\n\nğŸ’¡ å»ºè®®: è¯·æ±‚ä½“è¿‡å¤§ï¼ˆå½“å‰çº¦{total_request_size / 1024:.1f}KBï¼‰"
                    error_msg += f"\n  - å°è¯•å‡å° max_file_size_mb å‚æ•°ï¼ˆå½“å‰: {max_file_size_mb}MBï¼‰"
                    error_msg += f"\n  - æˆ–ä½¿ç”¨æ›´å°çš„è¾“å…¥å›¾åƒ"
                elif 'invalid_mask_image_format' in error_code.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: é®ç½©å›¾åƒæ ¼å¼ä¸æ­£ç¡®"
                    error_msg += "\n  - é®ç½©å›¾åƒå¿…é¡»æ˜¯PNGæ ¼å¼ä¸”åŒ…å«alphaé€šé“"
                    error_msg += "\n  - ç™½è‰²åŒºåŸŸè¡¨ç¤ºè¦ç¼–è¾‘çš„éƒ¨åˆ†ï¼Œé»‘è‰²åŒºåŸŸä¿æŒä¸å˜"
                elif 'unknown_parameter' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥APIå‚æ•°æ˜¯å¦æ­£ç¡®ï¼ŒæŸäº›å‚æ•°å¯èƒ½ä¸è¢«å½“å‰ç‰ˆæœ¬æ”¯æŒ"
                elif 'invalid_value' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥å‚æ•°å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…"
                elif 'invalid_request_error' in error_type.lower():
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå¿…éœ€å‚æ•°"
                elif response.status_code == 401:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆï¼Œè”ç³» @äºæ·¼ è·å–æ­£ç¡®çš„ä¸‡æ“ç½‘å…³key"
                elif response.status_code == 429:
                    error_msg += "\n\nğŸ’¡ å»ºè®®: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                
                raise ValueError(f"APIé”™è¯¯ [{error_code}]: {error_msg}")
            
            # å¤„ç†ç¼–è¾‘åçš„å›¾åƒ
            images_tensor = []
            image_data_list = response_data.get('data', [])
            
            if not image_data_list:
                debug_info["error"] = "å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®"
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
                raise ValueError("å“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
            
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æˆåŠŸç”Ÿæˆ {len(image_data_list)} å¼ å›¾åƒ")
            
            for idx, item in enumerate(image_data_list):
                if 'b64_json' in item:
                    # å¤„ç† base64 ç¼–ç çš„å›¾åƒ
                    b64_data = item['b64_json']
                    image_bytes = base64.b64decode(b64_data)
                    result_image = Image.open(io.BytesIO(image_bytes))
                    
                    # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
                    if result_image.mode != 'RGB':
                        result_image = result_image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(result_image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å›¾åƒ {idx + 1}: {result_image.size}, æ¨¡å¼: {result_image.mode}")
                    
                elif 'url' in item:
                    # å¤„ç†URLå½¢å¼çš„å›¾åƒ
                    print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ”¶åˆ°å›¾åƒURL: {item['url']}")
                    print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è­¦å‘Š: è·³è¿‡URLå½¢å¼çš„å›¾åƒï¼Œå½“å‰ç‰ˆæœ¬ä»…æ”¯æŒbase64æ ¼å¼")
            
            if not images_tensor:
                debug_info["error"] = "æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®ï¼ˆä»…æ”¯æŒbase64æ ¼å¼ï¼‰"
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®ï¼ˆä»…æ”¯æŒbase64æ ¼å¼ï¼‰")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage = response_data.get('usage', {})
            usage_info = f"Tokenä½¿ç”¨æƒ…å†µ:\n"
            
            # å¤„ç†è¯¦ç»†çš„tokenä¿¡æ¯
            input_tokens = usage.get('input_tokens', 0)
            output_tokens = usage.get('output_tokens', 0)
            total_tokens = usage.get('total_tokens', input_tokens + output_tokens)
            
            usage_info += f"- è¾“å…¥Token: {input_tokens}\n"
            
            # å¦‚æœæœ‰è¯¦ç»†çš„è¾“å…¥tokenä¿¡æ¯
            input_details = usage.get('input_tokens_details', {})
            if input_details:
                image_tokens = input_details.get('image_tokens', 0)
                text_tokens = input_details.get('text_tokens', 0)
                usage_info += f"  - å›¾åƒToken: {image_tokens}\n"
                usage_info += f"  - æ–‡æœ¬Token: {text_tokens}\n"
            
            usage_info += f"- è¾“å‡ºToken: {output_tokens}\n"
            usage_info += f"- æ€»è®¡Token: {total_tokens}\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}\n"
            usage_info += f"- åŸå§‹å›¾åƒå‹ç¼©: {compressed_size} -> {len(image_data) / 1024:.1f}KB\n"
            if mask_data is not None:
                usage_info += f"- é®ç½©å›¾åƒå‹ç¼©: {mask_compressed_size} -> {len(mask_data) / 1024:.1f}KB"
            else:
                usage_info += f"- é®ç½©å›¾åƒ: æœªæä¾›ï¼ˆç¼–è¾‘æ•´ä¸ªå›¾åƒï¼‰"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(response_data, ensure_ascii=False, indent=2)
            
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å›¾åƒç¼–è¾‘å®Œæˆ")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            debug_info["error"] = f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰"
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚å›¾åƒç¼–è¾‘å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            debug_info["error"] = "ç½‘ç»œè¿æ¥é”™è¯¯"
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®")
        except requests.exceptions.RequestException as e:
            debug_info["error"] = f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            debug_info["error"] = f"æœªçŸ¥å¼‚å¸¸: {str(e)}"
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] === è¯¦ç»†è°ƒè¯•ä¿¡æ¯ ===")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚URL: {debug_info['url']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚å¤´: {debug_info['headers']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] è¯·æ±‚ä½“å¤§å°: {debug_info['request_size']:.1f}KB")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] æ–‡ä»¶ä¿¡æ¯: {json.dumps(debug_info['files_info'], ensure_ascii=False, indent=2)}")
            if debug_info["response_status"]:
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”çŠ¶æ€ç : {debug_info['response_status']}")
            if debug_info["response_content"]:
                print(f"[ä¸‡æ“ GPT ç¼–è¾‘] å“åº”å†…å®¹: {debug_info['response_content']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] é”™è¯¯: {debug_info['error']}")
            print(f"[ä¸‡æ“ GPT ç¼–è¾‘] ==================")
            raise ValueError(f"å›¾åƒç¼–è¾‘å¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "WanQingGPTImageEdit": WanQingGPTImageEditNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanQingGPTImageEdit": "ä¸‡æ“ GPT å›¾åƒç¼–è¾‘"
} 
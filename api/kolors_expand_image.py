import torch
import numpy as np
import requests
import time
import json
import base64
import io
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
import folder_paths

class KolorsExpandImageNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "environment": (["staging", "prod", "idc"], {
                    "default": "staging",
                    "tooltip": "é€‰æ‹©ä¸‡æ“ç½‘å…³ç¯å¢ƒ"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "tooltip": "ä¸‡æ“ç½‘å…³APIå¯†é’¥ (x-api-key)"
                }),
                "prompt": ("STRING", {
                    "default": "è‡ªç„¶æ‰©å±•å›¾ç‰‡å†…å®¹",
                    "multiline": True,
                    "tooltip": "æ‰©å±•å›¾ç‰‡æè¿°æç¤ºè¯"
                }),
                "model_name": (["kling-v2"], {
                    "default": "kling-v2",
                    "tooltip": "å¯å›¾æ¨¡å‹åç§°"
                }),
                "up_expansion_ratio": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "å‘ä¸Šæ‰©å±•æ¯”ä¾‹ï¼ˆ0.0ä¸ºä¸æ‰©å±•ï¼‰"
                }),
                "down_expansion_ratio": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "å‘ä¸‹æ‰©å±•æ¯”ä¾‹ï¼ˆ0.0ä¸ºä¸æ‰©å±•ï¼‰"
                }),
                "left_expansion_ratio": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "å‘å·¦æ‰©å±•æ¯”ä¾‹ï¼ˆ0.0ä¸ºä¸æ‰©å±•ï¼‰"
                }),
                "right_expansion_ratio": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "å‘å³æ‰©å±•æ¯”ä¾‹ï¼ˆ0.0ä¸ºä¸æ‰©å±•ï¼‰"
                }),
                "timeout": ("FLOAT", {
                    "default": 300.0,
                    "min": 60.0,
                    "max": 600.0,
                    "step": 10.0,
                    "tooltip": "æ€»è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "poll_interval": ("FLOAT", {
                    "default": 5.0,
                    "min": 1.0,
                    "max": 30.0,
                    "step": 1.0,
                    "tooltip": "è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰"
                })
            },
            "optional": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾åƒï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å›¾åƒURLï¼‰"
                }),
                "image_url": ("STRING", {
                    "default": "https://ark-project.tos-cn-beijing.volces.com/doc_image/seededit_i2i.jpeg",
                    "tooltip": "å›¾åƒURLï¼ˆå½“æœªæä¾›è¾“å…¥å›¾åƒæ—¶ä½¿ç”¨ï¼‰"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("images", "response_json", "usage_info")
    FUNCTION = "expand_image"
    CATEGORY = "âœ¨âœ¨âœ¨design-ai/api"

    def __init__(self):
        self.environments = {
            "staging": "https://llm-gateway-staging.corp.kuaishou.com",
            "prod": "https://llm-gateway-prod.corp.kuaishou.com", 
            "idc": "http://llm-gateway.internal"
        }

    def tensor_to_base64(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºbase64ç¼–ç çš„å›¾åƒ"""
        # å¤„ç†batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor[0]
        
        # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿åœ¨0-255èŒƒå›´å†…
        np_image = tensor.cpu().numpy()
        if np_image.max() <= 1.0:
            np_image = (np_image * 255).astype(np.uint8)
        else:
            np_image = np.clip(np_image, 0, 255).astype(np.uint8)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(np_image)
        
        # è½¬æ¢ä¸ºbase64
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        buffer.seek(0)
        
        # è¿”å›çº¯base64å­—ç¬¦ä¸²ï¼ˆæ‰©å›¾APIå¯èƒ½ä¸éœ€è¦data URIå‰ç¼€ï¼‰
        base64_string = base64.b64encode(buffer.getvalue()).decode('utf-8')
        return base64_string

    def submit_task(self, environment, api_key, payload):
        """æäº¤æ‰©å±•ä»»åŠ¡"""
        base_url = self.environments[environment]
        url = f"{base_url}/ai-serve/v1/ktu/images/editing/expand"
        
        headers = {
            "x-api-key": api_key.strip(),
            "Content-Type": "application/json",
            "User-Agent": "ComfyUI-Kolors-Expand/1.0"
        }
        
        print(f"[å¯å›¾æ‰©å›¾] æäº¤ä»»åŠ¡åˆ°: {url}")
        print(f"[å¯å›¾æ‰©å›¾] è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        
        print(f"[å¯å›¾æ‰©å›¾] å“åº”çŠ¶æ€ç : {response.status_code}")
        print(f"[å¯å›¾æ‰©å›¾] å“åº”å¤´: {dict(response.headers)}")
        
        try:
            response_data = response.json()
            print(f"[å¯å›¾æ‰©å›¾] å“åº”æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
        except json.JSONDecodeError:
            response_text = response.text if response.text else "ç©ºå“åº”"
            print(f"[å¯å›¾æ‰©å›¾] å“åº”æ–‡æœ¬: {response_text}")
            raise ValueError(f"æ— æ•ˆçš„JSONå“åº” (çŠ¶æ€ç : {response.status_code}): {response_text}")
        
        if not response.ok:
            error_msg = response_data.get('message', 'æœªçŸ¥é”™è¯¯')
            if "too large" in error_msg.lower():
                raise ValueError(f"æ‰©å±•å‚æ•°è¿‡å¤§ï¼š{error_msg}\n\nğŸ’¡ å»ºè®®ï¼š\n1. é™ä½æ‰©å±•æ¯”ä¾‹ï¼ˆå»ºè®®æ€»æ‰©å±•ä¸è¶…è¿‡åŸå›¾3å€ï¼‰\n2. ä½¿ç”¨è¾ƒå°çš„åŸå§‹å›¾åƒ\n3. åˆ†æ­¥è¿›è¡Œæ‰©å±•")
            raise ValueError(f"ä»»åŠ¡æäº¤å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {error_msg}")
        
        if response_data.get('code') != 0:
            error_msg = response_data.get('message', 'æœªçŸ¥é”™è¯¯')
            if "too large" in error_msg.lower():
                raise ValueError(f"æ‰©å±•å‚æ•°è¿‡å¤§ï¼š{error_msg}\n\nğŸ’¡ å»ºè®®ï¼š\n1. é™ä½æ‰©å±•æ¯”ä¾‹ï¼ˆå»ºè®®æ€»æ‰©å±•ä¸è¶…è¿‡åŸå›¾3å€ï¼‰\n2. ä½¿ç”¨è¾ƒå°çš„åŸå§‹å›¾åƒ\n3. åˆ†æ­¥è¿›è¡Œæ‰©å±•")
            raise ValueError(f"ä»»åŠ¡æäº¤å¤±è´¥: {error_msg}")
        
        return response_data.get('data', {})

    def poll_task_result(self, environment, api_key, task_id, timeout, poll_interval):
        """è½®è¯¢ä»»åŠ¡ç»“æœ"""
        base_url = self.environments[environment]
        url = f"{base_url}/ai-serve/v1/ktu/images/editing/expand/{task_id}"
        
        headers = {
            "x-api-key": api_key.strip(),
            "User-Agent": "ComfyUI-Kolors-Expand/1.0"
        }
        
        print(f"[å¯å›¾æ‰©å›¾] è½®è¯¢URL: {url}")
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            print(f"[å¯å›¾æ‰©å›¾] è½®è¯¢ä»»åŠ¡çŠ¶æ€: {task_id}")
            
            try:
                response = requests.get(url, headers=headers, timeout=30)
                response_data = response.json()
                
                print(f"[å¯å›¾æ‰©å›¾] è½®è¯¢å“åº”çŠ¶æ€ç : {response.status_code}")
                print(f"[å¯å›¾æ‰©å›¾] è½®è¯¢å“åº”æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
                
                if not response.ok:
                    error_msg = response_data.get('message', 'æœªçŸ¥é”™è¯¯')
                    raise ValueError(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {error_msg}")
                
                if response_data.get('code') != 0:
                    error_msg = response_data.get('message', 'æœªçŸ¥é”™è¯¯')
                    raise ValueError(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {error_msg}")
                
                data = response_data.get('data', {})
                task_status = data.get('task_status', '')
                
                print(f"[å¯å›¾æ‰©å›¾] ä»»åŠ¡çŠ¶æ€: {task_status}")
                
                if task_status == 'succeed':
                    return response_data
                elif task_status == 'failed':
                    error_msg = data.get('fail_reason', 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥')
                    raise ValueError(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {error_msg}")
                elif task_status in ['submitted', 'processing']:
                    time.sleep(poll_interval)
                    continue
                else:
                    print(f"[å¯å›¾æ‰©å›¾] æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {task_status}")
                    time.sleep(poll_interval)
                    continue
                    
            except requests.exceptions.RequestException as e:
                print(f"[å¯å›¾æ‰©å›¾] è½®è¯¢è¯·æ±‚å¤±è´¥: {str(e)}")
                time.sleep(poll_interval)
                continue
        
        raise ValueError(f"ä»»åŠ¡è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œè¯·ç¨åé‡è¯•æˆ–å¢åŠ è¶…æ—¶æ—¶é—´")

    def expand_image(self, environment, api_key, prompt, model_name, 
                    up_expansion_ratio, down_expansion_ratio, left_expansion_ratio, right_expansion_ratio,
                    timeout, poll_interval, image=None, image_url=None):
        """
        å¯å›¾æ‰©å›¾
        """
        try:
            # éªŒè¯å¿…éœ€å‚æ•°
            if not api_key or api_key.strip() == "":
                raise ValueError("API Keyä¸èƒ½ä¸ºç©ºï¼Œè¯·è”ç³» @äºæ·¼ è·å–ä¸‡æ“ç½‘å…³key")
            
            if not prompt or prompt.strip() == "":
                raise ValueError("æç¤ºè¯ä¸èƒ½ä¸ºç©º")

            # æ£€æŸ¥æ‰©å±•æ¯”ä¾‹
            total_expansion = up_expansion_ratio + down_expansion_ratio + left_expansion_ratio + right_expansion_ratio
            if total_expansion > 4:  # ä¿å®ˆä¼°è®¡ï¼Œæ€»æ‰©å±•ä¸è¶…è¿‡åˆç†èŒƒå›´
                print(f"[å¯å›¾æ‰©å›¾] è­¦å‘Š: æ‰©å±•æ¯”ä¾‹è¾ƒå¤§ï¼ˆæ€»è®¡: {total_expansion:.1f}ï¼‰ï¼Œå¯èƒ½å¯¼è‡´å¤±è´¥ã€‚å»ºè®®é™ä½æ‰©å±•æ¯”ä¾‹ã€‚")

            # å¤„ç†è¾“å…¥å›¾åƒ
            image_input = None
            if image is not None:
                # ä½¿ç”¨æä¾›çš„å›¾åƒtensorï¼Œè½¬æ¢ä¸ºbase64
                image_input = self.tensor_to_base64(image)
                print(f"[å¯å›¾æ‰©å›¾] ä½¿ç”¨è¾“å…¥å›¾åƒtensorï¼Œå°ºå¯¸: {image.shape}")
                print(f"[å¯å›¾æ‰©å›¾] Base64å‰ç¼€: {image_input[:50]}...")
            elif image_url and image_url.strip():
                # ä½¿ç”¨å›¾åƒURL
                image_input = image_url.strip()
                print(f"[å¯å›¾æ‰©å›¾] ä½¿ç”¨å›¾åƒURL: {image_input}")
            else:
                raise ValueError("å¿…é¡»æä¾›è¾“å…¥å›¾åƒæˆ–å›¾åƒURL")

            # æ„å»ºè¯·æ±‚ä½“
            payload = {
                "model_name": model_name,
                "prompt": prompt.strip(),
                "image": image_input,
                "up_expansion_ratio": up_expansion_ratio,
                "down_expansion_ratio": down_expansion_ratio,
                "left_expansion_ratio": left_expansion_ratio,
                "right_expansion_ratio": right_expansion_ratio
            }
            
            # æäº¤ä»»åŠ¡
            task_data = self.submit_task(environment, api_key, payload)
            task_id = task_data.get('task_id')
            
            if not task_id:
                raise ValueError("ä»»åŠ¡æäº¤æˆåŠŸä½†æœªè·å–åˆ°task_id")
            
            print(f"[å¯å›¾æ‰©å›¾] ä»»åŠ¡å·²æäº¤ï¼Œtask_id: {task_id}")
            
            # è½®è¯¢ä»»åŠ¡ç»“æœ
            result_data = self.poll_task_result(environment, api_key, task_id, timeout, poll_interval)
            
            # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
            data = result_data.get('data', {})
            print(f"[å¯å›¾æ‰©å›¾] å®Œæ•´å“åº”æ•°æ®ç»“æ„:")
            print(f"[å¯å›¾æ‰©å›¾] result_data keys: {list(result_data.keys())}")
            print(f"[å¯å›¾æ‰©å›¾] data keys: {list(data.keys())}")
            
            # æ ¹æ®å®é™…APIå“åº”ç»“æ„æå–å›¾åƒ
            task_result = data.get('task_result', {})
            images_data = task_result.get('images', [])
            
            print(f"[å¯å›¾æ‰©å›¾] task_result keys: {list(task_result.keys())}")
            print(f"[å¯å›¾æ‰©å›¾] images_data: {images_data}")
            
            # æå–å›¾åƒURLåˆ—è¡¨
            image_urls = []
            if images_data:
                for img in images_data:
                    if isinstance(img, dict) and 'url' in img:
                        image_urls.append(img['url'])
                    elif isinstance(img, str):
                        image_urls.append(img)
            
            print(f"[å¯å›¾æ‰©å›¾] æå–åˆ°çš„å›¾åƒURLs: {image_urls}")
            
            if not image_urls:
                print(f"[å¯å›¾æ‰©å›¾] æœªæ‰¾åˆ°å›¾åƒæ•°æ®ï¼Œå®Œæ•´task_result: {json.dumps(task_result, ensure_ascii=False, indent=2)}")
                raise ValueError("ä»»åŠ¡å®Œæˆä½†æ²¡æœ‰ç”Ÿæˆå›¾åƒæ•°æ®")
            
            print(f"[å¯å›¾æ‰©å›¾] æˆåŠŸç”Ÿæˆ {len(image_urls)} å¼ å›¾åƒ")
            
            images_tensor = []
            for idx, image_url in enumerate(image_urls):
                print(f"[å¯å›¾æ‰©å›¾] ä¸‹è½½å›¾åƒ {idx + 1}: {image_url}")
                
                try:
                    img_response = requests.get(image_url, timeout=60)
                    img_response.raise_for_status()
                    result_image = Image.open(io.BytesIO(img_response.content))
                    
                    # è½¬æ¢ä¸ºRGB
                    if result_image.mode != 'RGB':
                        result_image = result_image.convert('RGB')
                    
                    # è½¬æ¢ä¸ºtensor
                    image_np = np.array(result_image).astype(np.float32) / 255.0
                    image_tensor = torch.from_numpy(image_np)[None,]
                    images_tensor.append(image_tensor)
                    
                    print(f"[å¯å›¾æ‰©å›¾] å›¾åƒ {idx + 1}: {result_image.size}, æ¨¡å¼: {result_image.mode}")
                    
                except Exception as e:
                    print(f"[å¯å›¾æ‰©å›¾] ä¸‹è½½å›¾åƒå¤±è´¥: {str(e)}")
                    continue
            
            if not images_tensor:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„å›¾åƒæ•°æ®")
            
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            result_images = torch.cat(images_tensor, dim=0)
            
            # æ ¼å¼åŒ–ä½¿ç”¨ä¿¡æ¯
            usage_info = f"å¯å›¾æ‰©å›¾ç»“æœ:\n"
            usage_info += f"- æ¨¡å‹: {model_name}\n"
            usage_info += f"- ä»»åŠ¡ID: {task_id}\n"
            usage_info += f"- æç¤ºè¯: {prompt.strip()}\n"
            usage_info += f"- è¾“å…¥å›¾åƒ: {'Tensor (base64)' if image is not None else 'URL'}\n"
            usage_info += f"- ä¸Šæ‰©å±•: {up_expansion_ratio:.1f} ({'ä¸æ‰©å±•' if up_expansion_ratio == 0 else f'+{up_expansion_ratio*100:.0f}%'})\n"
            usage_info += f"- ä¸‹æ‰©å±•: {down_expansion_ratio:.1f} ({'ä¸æ‰©å±•' if down_expansion_ratio == 0 else f'+{down_expansion_ratio*100:.0f}%'})\n"
            usage_info += f"- å·¦æ‰©å±•: {left_expansion_ratio:.1f} ({'ä¸æ‰©å±•' if left_expansion_ratio == 0 else f'+{left_expansion_ratio*100:.0f}%'})\n"
            usage_info += f"- å³æ‰©å±•: {right_expansion_ratio:.1f} ({'ä¸æ‰©å±•' if right_expansion_ratio == 0 else f'+{right_expansion_ratio*100:.0f}%'})\n"
            usage_info += f"- ç”Ÿæˆå›¾åƒæ•°é‡: {len(images_tensor)}"
            
            # è¿”å›å®Œæ•´çš„å“åº”JSON
            response_json = json.dumps(result_data, ensure_ascii=False, indent=2)
            
            print(f"[å¯å›¾æ‰©å›¾] å›¾åƒæ‰©å±•å®Œæˆ")
            print(f"[å¯å›¾æ‰©å›¾] {usage_info}")
            
            return (result_images, response_json, usage_info)
            
        except requests.exceptions.Timeout:
            raise ValueError(f"è¯·æ±‚è¶…æ—¶ã€‚å›¾åƒæ‰©å±•å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å¢åŠ è¶…æ—¶æ—¶é—´ã€‚")
        except requests.exceptions.ConnectionError:
            raise ValueError(f"ç½‘ç»œè¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥:\n1. ç½‘ç»œè¿æ¥\n2. ä¸‡æ“ç½‘å…³åœ°å€æ˜¯å¦å¯è®¿é—®\n3. ç¯å¢ƒé€‰æ‹©æ˜¯å¦æ­£ç¡®")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            raise ValueError(f"å›¾åƒæ‰©å±•å¤±è´¥: {str(e)}")

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "KolorsExpandImage": KolorsExpandImageNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KolorsExpandImage": "å¯å›¾æ‰©å›¾"
} 